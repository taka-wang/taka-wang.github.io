<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Liberation Notes</title>
    <link>https://blog.cmwang.net/zh/tags/ai/</link>
    <description>Recent content in AI on Liberation Notes</description>
    <image>
      <title>Liberation Notes</title>
      <url>https://blog.cmwang.net/47</url>
      <link>https://blog.cmwang.net/47</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 19 Oct 2023 19:59:44 +0800</lastBuildDate><atom:link href="https://blog.cmwang.net/zh/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>帶有進度條的 Faster Whisper</title>
      <link>https://blog.cmwang.net/zh/posts/2023/10/faster-whisper-in-python3/</link>
      <pubDate>Thu, 19 Oct 2023 19:59:44 +0800</pubDate>
      
      <guid>https://blog.cmwang.net/zh/posts/2023/10/faster-whisper-in-python3/</guid>
      <description>如何使用 faster-whisper 並產生進度條，你可以用它來幫影片自動產生字幕</description>
      <content:encoded><![CDATA[<p><a href="https://github.com/guillaumekln/faster-whisper">faster-whisper</a> 使用<code>CTranslate2</code>重新實現 OpenAI 的 Whisper 模型，<code>CTranslate2</code>是一個用於 Transformer 模型快速推論的引擎。整體速度提升不少，前提還是要有 GPU。</p>
<p>以下是產生字幕的簡單範例，請先安裝 <code>faster_whisper</code> 與 <code>pysubs2</code></p>


<div class="terminal space shadow">
    <div class="top">
        <div class="btns">
            <span class="circle red"></span>
            <span class="circle yellow"></span>
            <span class="circle green"></span>
        </div>
        <div class="title">
            transcribe without progress bar
        </div>
    </div>
    <div class="terminalbody"><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># pip install faster_whisper pysubs2</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">faster_whisper</span> <span class="kn">import</span> <span class="n">WhisperModel</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pysubs2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">WhisperModel</span><span class="p">(</span><span class="n">model_size</span> <span class="o">=</span> <span class="s1">&#39;large-v2&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">segments</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="o">=</span><span class="s1">&#39;audio.mp3&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># to use pysubs2, the argument must be a segment list-of-dicts</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span><span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">segments</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">segment_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;start&#39;</span><span class="p">:</span><span class="n">s</span><span class="o">.</span><span class="n">start</span><span class="p">,</span><span class="s1">&#39;end&#39;</span><span class="p">:</span><span class="n">s</span><span class="o">.</span><span class="n">end</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">:</span><span class="n">s</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">segment_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">subs</span> <span class="o">=</span> <span class="n">pysubs2</span><span class="o">.</span><span class="n">load_from_whisper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">subs</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;output.srt&#39;</span><span class="p">)</span> <span class="c1">#save srt file</span>
</span></span></code></pre></div></div>
</div>
<br />

<p>我們可以這樣改寫，讓他透過 tqdm 產生進度條</p>


<div class="terminal space shadow">
    <div class="top">
        <div class="btns">
            <span class="circle red"></span>
            <span class="circle yellow"></span>
            <span class="circle green"></span>
        </div>
        <div class="title">
            transcribe with progress bar
        </div>
    </div>
    <div class="terminalbody"><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">faster_whisper</span> <span class="kn">import</span> <span class="n">WhisperModel</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pysubs2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">WhisperModel</span><span class="p">(</span><span class="n">model_size</span> <span class="o">=</span> <span class="s1">&#39;large-v2&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">segments</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="o">=</span><span class="s1">&#39;audio.mp3&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># Prepare results for SRT file format</span>
</span></span><span class="line"><span class="cl">  <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="n">timestamps</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># for progress bar</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">info</span><span class="o">.</span><span class="n">duration</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&#34; audio seconds&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="n">seg</span> <span class="ow">in</span> <span class="n">segments</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">segment_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;start&#39;</span><span class="p">:</span> <span class="n">seg</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">:</span> <span class="n">seg</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">seg</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">          <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">segment_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># Update progress bar based on segment duration</span>
</span></span><span class="line"><span class="cl">          <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">seg</span><span class="o">.</span><span class="n">end</span> <span class="o">-</span> <span class="n">timestamps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="n">timestamps</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># Handle silence at the end of the audio</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">timestamps</span> <span class="o">&lt;</span> <span class="n">info</span><span class="o">.</span><span class="n">duration</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">duration</span> <span class="o">-</span> <span class="n">timestamps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">subs</span> <span class="o">=</span> <span class="n">pysubs2</span><span class="o">.</span><span class="n">load_from_whisper</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">subs</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;output.srt&#39;</span><span class="p">)</span> <span class="c1">#save srt file</span>
</span></span></code></pre></div></div>
</div>
<br />

<p>順便附上 Docker file</p>


<div class="terminal space shadow">
    <div class="top">
        <div class="btns">
            <span class="circle red"></span>
            <span class="circle yellow"></span>
            <span class="circle green"></span>
        </div>
        <div class="title">
            Dockerfile
        </div>
    </div>
    <div class="terminalbody"><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># Use the official NVIDIA CUDA image as the base image</span>
</span></span><span class="line"><span class="cl">FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu20.04
</span></span><span class="line"><span class="cl">ARG <span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Install necessary dependencies</span>
</span></span><span class="line"><span class="cl">RUN apt-get update <span class="o">&amp;&amp;</span> apt-get install -y <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    wget <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    python3 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    python3-pip <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    <span class="o">&amp;&amp;</span> apt-get clean <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    <span class="o">&amp;&amp;</span> rm -rf /var/lib/apt/lists/*
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set the working directory inside the container</span>
</span></span><span class="line"><span class="cl">WORKDIR /app
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Install required Python packages</span>
</span></span><span class="line"><span class="cl">RUN pip install faster_whisper pysubs2
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create directories to store the models</span>
</span></span><span class="line"><span class="cl">RUN mkdir -p /models/faster-whisper-medium
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Download the medium model using wget to the specified directory</span>
</span></span><span class="line"><span class="cl">RUN wget -O /models/faster-whisper-medium/config.json https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/config.json <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    wget -O /models/faster-whisper-medium/model.bin https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/model.bin <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    wget -O /models/faster-whisper-medium/tokenizer.json https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/tokenizer.json <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    wget -O /models/faster-whisper-medium/vocabulary.txt https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/vocabulary.txt
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">COPY app.py /app/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run script</span>
</span></span><span class="line"><span class="cl">CMD <span class="o">[</span><span class="s2">&#34;python3&#34;</span>, <span class="s2">&#34;app.py&#34;</span><span class="o">]</span>
</span></span></code></pre></div></div>
</div>
<br />

<p><strong>Source Code</strong>: <a href="https://github.com/taka-wang/docker-whisper">https://github.com/taka-wang/docker-whisper</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>不同凡響 - AI (Ken Lin)</title>
      <link>https://blog.cmwang.net/zh/posts/2023/10/think-different-ai-ken/</link>
      <pubDate>Tue, 10 Oct 2023 19:23:34 +0800</pubDate>
      
      <guid>https://blog.cmwang.net/zh/posts/2023/10/think-different-ai-ken/</guid>
      <description>此AI生成的旁白僅供娛樂，嚴禁商業使用。</description>
      <content:encoded><![CDATA[<p><code>Ken Lin</code> 是我的朋友，這是他的 AI Clone 版<strong>不同凡響 (Think Different)</strong>。</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube-nocookie.com/embed/Yi99xxPv7fs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    
    <item>
      <title>Grown Ups - AI (Lee Ji Eun)</title>
      <link>https://blog.cmwang.net/zh/posts/2023/10/grown-ups/</link>
      <pubDate>Tue, 10 Oct 2023 17:12:22 +0800</pubDate>
      
      <guid>https://blog.cmwang.net/zh/posts/2023/10/grown-ups/</guid>
      <description>Disclaimer: Songs generated by this AI are for entertainment purposes only and strictly prohibited for commercial use. Not liable for legal consequences.</description>
      <content:encoded><![CDATA[
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube-nocookie.com/embed/eJmHLJNzOII" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-md" data-lang="md"><span class="line"><span class="cl">詞：서동성、이치훈／曲：박성일／編曲： 박성일、엉클샘
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">고단한 하루 끝에 떨구는 눈물
</span></span><span class="line"><span class="cl">孤單的一天的盡頭 落下的淚水
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">난 어디를 향해 가는 걸까
</span></span><span class="line"><span class="cl">我到底朝向哪裡走去
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">아플 만큼 아팠다 생각했는데
</span></span><span class="line"><span class="cl">還以為心已經痛到不能再痛了
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">아직도 한참 남은 건가 봐
</span></span><span class="line"><span class="cl">不過似乎又還有一段距離
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">이 넓은 세상에 혼자인 것처럼
</span></span><span class="line"><span class="cl">在這廣大的世界裡 我總像獨自一人般
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">아무도 내 맘을 보려 하지 않고
</span></span><span class="line"><span class="cl">沒有誰願意看見我的心
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">아무도
</span></span><span class="line"><span class="cl">沒有任何人
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">눈을 감아 보면
</span></span><span class="line"><span class="cl">若是閉上雙眼
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">내게 보이는 내 모습
</span></span><span class="line"><span class="cl">我所能看見的 自己的模樣
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">지치지 말고
</span></span><span class="line"><span class="cl">不再有疲倦
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">잠시 멈추라고
</span></span><span class="line"><span class="cl">暫時停下腳步
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">갤 것 같지 않던
</span></span><span class="line"><span class="cl">像是散不開的
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">짙은 나의 어둠은
</span></span><span class="line"><span class="cl">我深沉的黑暗
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">나를 버리면
</span></span><span class="line"><span class="cl">如果將我拋下
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">모두 갤 거라고
</span></span><span class="line"><span class="cl">所有就能揮之而去吧
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">웃는 사람들 틈에 이방인처럼
</span></span><span class="line"><span class="cl">在笑著的人群之中 就像個異類
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">혼자만 모든 걸 잃은 표정
</span></span><span class="line"><span class="cl">獨自掛著失去一切的表情
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">정신없이 한참을 뛰었던 걸까
</span></span><span class="line"><span class="cl">提不起精神地 奔跑了好一陣子
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">이제는 너무 멀어진 꿈들
</span></span><span class="line"><span class="cl">現在已經離得太遙遠的夢想
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">이 오랜 슬픔이 그치기는 할까
</span></span><span class="line"><span class="cl">這漫長的悲傷會結束嗎
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">언제가 한 번쯤 따스한 햇살이 내릴까
</span></span><span class="line"><span class="cl">總有一天 溫暖的陽光會灑下吧
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">나는 내가 되고 별은 영원히 빛나고
</span></span><span class="line"><span class="cl">我成為我自己 如星星永遠閃耀
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">잠들지 않는 꿈을 꾸고 있어
</span></span><span class="line"><span class="cl">幻想著不會沉睡的夢
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">바보 같은 나는 내가 될 수 없단 걸
</span></span><span class="line"><span class="cl">傻瓜般的我 是無法成為我的
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">눈을 뜨고야 그걸 알게 됐죠
</span></span><span class="line"><span class="cl">這是張開雙眼 才會知道的
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">어떤 날 어떤 시간 어떤 곳에서
</span></span><span class="line"><span class="cl">某一天 某一個時間 在某個地方
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">나의 작은 세상은 웃어줄까
</span></span><span class="line"><span class="cl">我那小小的世界 會對我微笑嗎
</span></span></code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>YOLOv7 TensorRT 的性能測試</title>
      <link>https://blog.cmwang.net/zh/posts/2022/07/performance-benchmarking-of-yolov7-tensorrt/</link>
      <pubDate>Mon, 25 Jul 2022 10:30:00 +0000</pubDate>
      
      <guid>https://blog.cmwang.net/zh/posts/2022/07/performance-benchmarking-of-yolov7-tensorrt/</guid>
      <description>這篇文章只有英文版的</description>
      <content:encoded><![CDATA[<p><img loading="lazy" src="images/1.gif#layoutTextWidth" alt="image"  />

YOLOv7 TensorRT Performance Benchmarking.</p>
<p>Object detection is one of the fundamental problems of computer vision. Instead of region detection and object classification separately in two stage detectors, object classification and bounding-box regression are done directly without using pre-generated region proposals in one stage detectors. YOLO (You Only Look Once) is one of the representative models of one-stage architecture. The YOLO family has continued to evolve since 2016, this summer we’ve got its latest update to version 7.</p>
<p><a href="https://github.com/WongKinYiu/yolov7">GitHub - WongKinYiu/yolov7: Implementation of paper - YOLOv7: Trainable bag-of-freebies sets new…</a></p>
<p>If you are trying to learn how to train your model on a custom dataset from the beginning, there are already many tutorials, notebooks and videos available online. In <a href="https://nilvana.ai/">Nilvana</a>, we really care about its real-world performance on the embedded devices, especially Nvidia Jetson family devices. So we conducted a series performance testing of YOLOv7 variants models on different devices, from cloud GPUs A100 to the latest tiny powerhouse <a href="https://developer.nvidia.com/embedded/jetson-orin">AGX Orin</a>.</p>
<p><a href="https://www.seeedstudio.com/NVIDIA-Jetson-AGX-Orin-Developer-Kit-p-5314.html">NVIDIA® Jetson AGX Orin™ Developer Kit: smallest and most powerful AI edge computer</a></p>
<blockquote>
<p>The main reason YOLOv7 is more accurate, compare to other models with similar AP, YOLOv7 has only about half computational cost. — <a href="https://github.com/WongKinYiu/yolov7/issues/207#issuecomment-1186934294">WongKinYiu</a> &gt; <img loading="lazy" src="images/2.png#layoutTextWidth" alt="image"  />

Input and Output shape of YOLOv7 (80 class)</p>
</blockquote>
<p>According to the results table, Xavier NX can run YOLOv7-tiny model pretty well. AGX Orin can even run YOLOv7x model more than 30 FPS, it’s amazing!</p>
<p><img loading="lazy" src="images/3.png" alt="image"  />

<em>End-to-End Performance on 1080P video, Batch Size=1</em></p>
<p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube-nocookie.com/embed/OypXod2zaoQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<em>Performance Benchmarking Playlist</em></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
