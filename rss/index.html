<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Liberation Notes]]></title><description><![CDATA[This is me thinking about life and software, discovering old lessons and learning new stuff.]]></description><link>https://blog.cmwang.net/</link><image><url>https://blog.cmwang.net/favicon.png</url><title>Liberation Notes</title><link>https://blog.cmwang.net/</link></image><generator>Ghost 5.78</generator><lastBuildDate>Wed, 31 Jan 2024 16:23:47 GMT</lastBuildDate><atom:link href="https://blog.cmwang.net/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[迷途 (Astray) - AI (Lee Ji Eun)]]></title><description><![CDATA[Disclaimer: Songs generated by this AI are for entertainment purposes only and strictly prohibited for commercial use. Not liable for legal consequences.]]></description><link>https://blog.cmwang.net/ai-iu-astray/</link><guid isPermaLink="false">65ba5e4dd5373f88eb1a0a5d</guid><category><![CDATA[AI]]></category><category><![CDATA[IU]]></category><dc:creator><![CDATA[Jamie Wang]]></dc:creator><pubDate>Tue, 14 Nov 2023 07:51:00 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/2024/01/1616593-1.jpg" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/_1oCs-Tx5Jc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen title="&#x8FF7;&#x9014; - AI IU"></iframe></figure><img src="https://blog.cmwang.net/content/images/2024/01/1616593-1.jpg" alt="&#x8FF7;&#x9014; (Astray) - AI (Lee Ji Eun)"><p>&#x8A5E;&#xFF1A;&#x6797;&#x963F;&#x8207; &#x66F2;&#xFF1A;&#x912D;&#x51B0;&#x51B0;</p>
<p>&#x9ED1;&#x591C;&#x64A5;&#x52D5;&#x6642;&#x91DD;<br>
&#x55A7;&#x56C2;&#x9010;&#x6F38;&#x4EE3;&#x66FF;&#x7121;&#x8072;<br>
&#x6211;&#x5011;&#x6F14;&#x8457;&#x76F8;&#x9047;&#x5287;&#x672C;<br>
&#x9472;&#x5D4C;&#x591C;&#x7684;&#x5F69;&#x8679;<br>
&#x9084;&#x6709;&#x7A7F;&#x904E;&#x6C99;&#x6F20;&#x7684;&#x98A8;<br>
&#x90FD;&#x66FE;&#x7D93;&#x662F;&#x6211;&#x5011;&#x7684;&#x898B;&#x8B49;</p>
<p>&#x8AB0;&#x4E0D;&#x662F;&#x832B;&#x832B;&#x4E2D;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x627E;&#x5C0B; &#x5104;&#x842C;&#x5206;&#x4E4B;&#x4E00;&#x7684;&#x53EF;&#x80FD;<br>
&#x56F0;&#x5728;&#x9019; &#x540D;&#x70BA;&#x547D;&#x904B;&#x7684;&#x57CE;<br>
&#x537B;&#x4F9D;&#x820A;&#x8FFD;&#x9010;&#x8457;&#x661F;&#x8FB0;<br>
&#x5225;&#x64D4;&#x5FC3; &#x6211;&#x611B;&#x8457;&#x7684;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x57F7;&#x676F;&#x9152; &#x6EAB;&#x6696;&#x5B64;&#x7368;&#x9748;&#x9B42;<br>
&#x8B93;&#x6211;&#x64C1;&#x62B1; &#x4F60;&#x7684;&#x88C2;&#x75D5;<br>
&#x4F60;&#x5982;&#x661F;&#x71E6;&#x721B; &#x9583;&#x720D;&#x5728;&#x843D;&#x5BDE;&#x6642;&#x5206;</p>
<p>&#x9ED1;&#x591C;&#x64A5;&#x52D5;&#x6642;&#x91DD;<br>
&#x55A7;&#x56C2;&#x9010;&#x6F38;&#x4EE3;&#x66FF;&#x7121;&#x8072;<br>
&#x6211;&#x5011;&#x6F14;&#x8457;&#x76F8;&#x9047;&#x5287;&#x672C;<br>
&#x9472;&#x5D4C;&#x591C;&#x7684;&#x5F69;&#x8679;<br>
&#x9084;&#x6709;&#x7A7F;&#x904E;&#x6C99;&#x6F20;&#x7684;&#x98A8;<br>
&#x90FD;&#x66FE;&#x7D93;&#x662F;&#x6211;&#x5011;&#x7684;&#x898B;&#x8B49;</p>
<p>&#x8AB0;&#x4E0D;&#x662F;&#x832B;&#x832B;&#x4E2D;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x627E;&#x5C0B; &#x5104;&#x842C;&#x5206;&#x4E4B;&#x4E00;&#x7684;&#x53EF;&#x80FD;<br>
&#x56F0;&#x5728;&#x9019; &#x540D;&#x70BA;&#x547D;&#x904B;&#x7684;&#x57CE;<br>
&#x537B;&#x4F9D;&#x820A;&#x8FFD;&#x9010;&#x8457;&#x661F;&#x8FB0;<br>
&#x5225;&#x64D4;&#x5FC3; &#x6211;&#x611B;&#x8457;&#x7684;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x57F7;&#x676F;&#x9152; &#x6EAB;&#x6696;&#x5B64;&#x7368;&#x9748;&#x9B42;<br>
&#x8B93;&#x6211;&#x64C1;&#x62B1; &#x4F60;&#x7684;&#x88C2;&#x75D5;<br>
&#x4F60;&#x5982;&#x661F;&#x71E6;&#x721B; &#x9583;&#x720D;&#x5728;&#x843D;&#x5BDE;&#x6642;&#x5206;</p>
<p>&#x8AB0;&#x4E0D;&#x662F;&#x832B;&#x832B;&#x4E2D;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x627E;&#x5C0B; &#x5104;&#x842C;&#x5206;&#x4E4B;&#x4E00;&#x7684;&#x53EF;&#x80FD;<br>
&#x56F0;&#x5728;&#x9019; &#x540D;&#x70BA;&#x547D;&#x904B;&#x7684;&#x57CE;<br>
&#x537B;&#x4F9D;&#x820A;&#x8FFD;&#x9010;&#x8457;&#x661F;&#x8FB0;<br>
&#x5225;&#x64D4;&#x5FC3; &#x6211;&#x611B;&#x8457;&#x7684;&#x8FF7;&#x9014;&#x7684;&#x4EBA;<br>
&#x57F7;&#x676F;&#x9152; &#x6EAB;&#x6696;&#x5B64;&#x7368;&#x9748;&#x9B42;<br>
&#x8B93;&#x6211;&#x64C1;&#x62B1; &#x4F60;&#x7684;&#x88C2;&#x75D5;<br>
&#x4F60;&#x5982;&#x661F;&#x71E6;&#x721B; &#x9583;&#x720D;&#x5728;&#x843D;&#x5BDE;&#x6642;&#x5206;</p>
]]></content:encoded></item><item><title><![CDATA[重啟人生 | BRUSH UP LIFE]]></title><description><![CDATA[《重啟人生》（ブラッシュアップライフ）是今年度最熱門的日劇之一，它深深觸動了許多人的心靈。]]></description><link>https://blog.cmwang.net/brush-up-life/</link><guid isPermaLink="false">65ba7277b102c4db988584e2</guid><category><![CDATA[ブラッシュアップライフ]]></category><category><![CDATA[日劇]]></category><category><![CDATA[Japanese Drama]]></category><category><![CDATA[Emotions]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Sun, 23 Apr 2023 10:36:21 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-qmnohe88z8o1ibeoayglua.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-qmnohe88z8o1ibeoayglua.png" alt="&#x91CD;&#x555F;&#x4EBA;&#x751F; | BRUSH UP LIFE"><p>&#x300A;&#x91CD;&#x555F;&#x4EBA;&#x751F;&#x300B;&#xFF08;&#x30D6;&#x30E9;&#x30C3;&#x30B7;&#x30E5;&#x30A2;&#x30C3;&#x30D7;&#x30E9;&#x30A4;&#x30D5;&#xFF09;&#x662F;&#x4ECA;&#x5E74;&#x5EA6;&#x6700;&#x71B1;&#x9580;&#x7684;&#x65E5;&#x5287;&#x4E4B;&#x4E00;&#xFF0C;&#x5B83;&#x6DF1;&#x6DF1;&#x89F8;&#x52D5;&#x4E86;&#x8A31;&#x591A;&#x4EBA;&#x7684;&#x5FC3;&#x9748;&#x3002;&#x5287;&#x4E2D;&#x878D;&#x5408;&#x4E86;&#x8A31;&#x591A;&#x5E73;&#x6210;&#x6642;&#x4EE3;&#x7684;&#x7D93;&#x5178;&#x5143;&#x7D20;&#xFF0C;&#x9084;&#x6709;&#x4E0D;&#x5C11;&#x6642;&#x4EE3;&#x7684;&#x773C;&#x6DDA;&#xFF0C;&#x5982;BB Call&#x3001;&#x305F;&#x307E;&#x3054;&#x3063;&#x3061;&#x3001;Game Boy Advance&#x7B49;&#x7B49;&#xFF0C;&#x52FE;&#x8D77;&#x4E86;&#x4EBA;&#x5011;&#x5C0D;&#x65BC;&#x5F80;&#x65E5;&#x6642;&#x5149;&#x7684;&#x7F8E;&#x597D;&#x56DE;&#x61B6;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x9019;&#x90E8;&#x5287;&#x7684;&#x97F3;&#x6A02;&#x4E5F;&#x5341;&#x5206;&#x8B1B;&#x7A76;&#xFF0C;&#x5176;&#x4E2D;&#x7684;&#x61F7;&#x820A;&#x65E5;&#x6587;&#x6B4C;&#x66F2;&#x66F4;&#x662F;&#x8B93;&#x4EBA;&#x56DE;&#x60F3;&#x8D77;&#x90A3;&#x4E9B;&#x5E74;&#x8F15;&#x6642;&#x7684;&#x7A2E;&#x7A2E;&#x3002;&#x6545;&#x4E8B;&#x60C5;&#x7BC0;&#x63CF;&#x5BEB;&#x4E86;&#x4E00;&#x751F;&#x646F;&#x53CB;&#x4E4B;&#x9593;&#x7684;&#x771F;&#x646F;&#x60C5;&#x8ABC;&#x8207;&#x65E5;&#x5E38;&#x9593;&#x7684;&#x9592;&#x804A;&#xFF0C;&#x6545;&#x4E8B;&#x76F8;&#x7576;&#x4EE4;&#x4EBA;&#x611F;&#x52D5;&#x3002;</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.kkbox.com/hk/tc/playlist/LZFv22FCYzN14uoKXl?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">&#x91CD;&#x555F;&#x4EBA;&#x751F;_&#x6B4C;&#x55AE;</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-op9c4ycwtorfx7pm.jpg" alt="&#x91CD;&#x555F;&#x4EBA;&#x751F; | BRUSH UP LIFE"></div></a></figure><!--kg-card-end: html--><p>&#x9019;&#x90E8;&#x5287;&#x7684;&#x7DE8;&#x5287; &#x30D0;&#x30AB;&#x30EA;&#x30BA;&#x30E0; &#x904E;&#x5F80;&#x66FE;&#x7D93;&#x5275;&#x4F5C;&#x51FA;&#x985E;&#x4F3C;&#x4E3B;&#x984C;&#x7684;&#x4F5C;&#x54C1;&#xFF0C;&#x4F8B;&#x5982;&#x300A;&#x7D20;&#x6575;&#x306A;&#x9078;TAXI&#x300B;&#xFF0C;&#x500B;&#x4EBA;&#x4E5F;&#x662F;&#x5F88;&#x63A8;&#x85A6;&#x9019;&#x500B;&#x8F15;&#x9B06;&#x5C0F;&#x54C1;&#x3002;&#x6211;&#x5728;&#x89C0;&#x5F71;&#x7684;&#x904E;&#x7A0B;&#x4E2D;&#xFF0C;&#x4E5F;&#x4E0D;&#x514D;&#x806F;&#x60F3;&#x5230;&#x53E6;&#x5916;&#x5169;&#x90E8;&#x76F8;&#x95DC;&#x984C;&#x6750;&#x7684;&#x4F5C;&#x54C1;&#xFF0C;&#x5206;&#x5225;&#x662F;&#x5E74;&#x4EE3;&#x6709;&#x9EDE;&#x4E45;&#x9060;&#x7684;&#x65E5;&#x5287;&#x300A;Loss:Time:Life&#x300B;&#xFF08;&#x30ED;&#x30B9;&#xFF1A;&#x30BF;&#x30A4;&#x30E0;&#xFF1A;&#x30E9;&#x30A4;&#x30D5;&#xFF09; &#x548C;&#x8FD1;&#x671F;&#x7684;&#x97D3;&#x5287;&#x300A;&#x8A8D;&#x8B58;&#x7684;&#x59BB;&#x5B50;&#x300B;&#xFF08;&#xC544;&#xB294;&#xC640;&#xC774;&#xD504;&#xFF09;&#xFF0C;&#x90FD;&#x662F;&#x767C;&#x4EBA;&#x7701;&#x601D;&#x4E5F;&#x5F88;&#x6709;&#x610F;&#x601D;&#x7684;&#x5F71;&#x96C6;&#x3002;&#x9019;&#x4E9B;&#x7A7F;&#x8D8A;&#x6216;&#x8005;&#x5E73;&#x884C;&#x5B87;&#x5B99;&#x7684;&#x5F71;&#x96C6;&#x96D6;&#x7136;&#x8457;&#x91CD;&#x7684;&#x5167;&#x5BB9;&#x4E0D;&#x540C;&#xFF0C;&#x4F46;&#x300A;&#x91CD;&#x555F;&#x4EBA;&#x751F;&#x300B;&#x537B;&#x4E0D;&#x540C;&#x65BC;&#x5176;&#x4ED6;&#x985E;&#x4F3C;&#x4F5C;&#x54C1;&#xFF0C;&#x5B83;&#x4E26;&#x4E0D;&#x8457;&#x91CD;&#x65BC;&#x4EBA;&#x751F;&#x7684;&#x61CA;&#x6094;&#x8207;&#x88DC;&#x6551;&#xFF0C;&#x53CD;&#x800C;&#x50CF;&#x662F;&#x6389;&#x5165;&#x4E0D;&#x540C;&#x5E73;&#x884C;&#x5B87;&#x5B99;&#x7684;&#x6642;&#x7A7A;&#x65C5;&#x8005;&#xFF0C;&#x91CD;&#x65B0;&#x518D;&#x904E;&#x4E00;&#x6B21;&#x4E0D;&#x540C;&#x7684;&#x4EBA;&#x751F;&#x3002;&#x96D6;&#x7136;&#x5728;&#x4E16;&#x754C;&#x89C0;&#x7684;&#x8A2D;&#x5B9A;&#x4E0A;&#x53EF;&#x80FD;&#x6703;&#x8B93;&#x4EBA;&#x6709;&#x9EDE;&#x56F0;&#x60D1;&#xFF0C;&#x611F;&#x89BA;&#x597D;&#x50CF;&#x6709;&#x4E00;&#x4E9B; Bug&#xFF0C;&#x4F46;&#x8ACB;&#x5E36;&#x8457;&#x6109;&#x6085;&#x7684;&#x5FC3;&#x60C5;&#xFF0C;&#x76E1;&#x60C5;&#x4EAB;&#x53D7;&#x9019;&#x90E8;&#x6EFF;&#x6EFF;&#x61F7;&#x820A;&#x98A8;&#x65E5;&#x5287;&#x60F3;&#x50B3;&#x9054;&#x7684;&#x6545;&#x4E8B;&#x5373;&#x53EF;&#x3002;</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.amazon.co.jp/%E3%83%AD%E3%82%B9-%E3%82%BF%E3%82%A4%E3%83%A0-%E3%83%A9%E3%82%A4%E3%83%95/dp/B0B8P9K1TS?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">&#x30ED;&#x30B9;:&#x30BF;&#x30A4;&#x30E0;:&#x30E9;&#x30A4;&#x30D5;</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-pne8z2_fdgsa0yx1.jpg" alt="&#x91CD;&#x555F;&#x4EBA;&#x751F; | BRUSH UP LIFE"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.viki.com/tv/35862c-familiar-wife?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Familiar Wife | Korea | Drama | Watch with English Subtitles &amp; More &#x2714;&#xFE0F;</div><div class="kg-bookmark-description">One unexpected choice can change everything about your life. Cha Joo Hyuk (Ji Sung) works at a bank and has been&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-ybzomdgs0pke-u_8.jpg" alt="&#x91CD;&#x555F;&#x4EBA;&#x751F; | BRUSH UP LIFE"></div></a></figure><!--kg-card-end: html--><p>&#x7576;&#x5F71;&#x7247;&#x4E2D;&#x97FF;&#x8D77; ZARD &#x7684;&#x300A;&#x8CA0;&#x3051;&#x306A;&#x3044;&#x3067;&#x300B;&#x6642;&#xFF0C;&#x6211;&#x7684;&#x5167;&#x5FC3;&#x4E0D;&#x7981;&#x611F;&#x5230;&#x6FC0;&#x52D5;&#x548C;&#x611F;&#x50B7;&#x3002;&#x5742;&#x4E95;&#x6CC9;&#x6C34;&#x7684;&#x97F3;&#x6A02;&#x66FE;&#x7D93;&#x966A;&#x4F34;&#x6211;&#x5EA6;&#x904E;&#x9752;&#x6F80;&#x5B64;&#x55AE;&#x7684;&#x5B78;&#x751F;&#x6642;&#x5149;&#xFF0C;&#x61F7;&#x820A;&#x97F3;&#x6A02;&#x771F;&#x7684;&#x70BA;&#x672C;&#x5287;&#x52A0;&#x5206;&#x4E0D;&#x5C11;&#xFF0C;&#x6BCF;&#x6BCF;&#x90FD;&#x5C07;&#x4EBA;&#x5E36;&#x56DE;&#x90A3;&#x500B;&#x55AE;&#x7D14;&#x7684;&#x5E74;&#x4EE3;&#x3002;</p><p>&#x4E3B;&#x4EBA;&#x516C;&#x5728;&#x5287;&#x4E2D;&#x6BCF;&#x4E00;&#x6B21;&#x7684;&#x91CD;&#x751F;&#x90FD;&#x662F;&#x70BA;&#x4E86;&#x80FD;&#x5920;&#x91CD;&#x65B0;&#x6295;&#x80CE;&#x6210;&#x70BA;&#x4EBA;&#x985E;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x4ED6;&#x91CD;&#x65B0;&#x52AA;&#x529B;&#x7A4D;&#x798F;&#x505A;&#x597D;&#x4E8B;&#xFF0C;&#x5F9E;&#x4E00;&#x958B;&#x59CB;&#x7684;&#x5C0F;&#x611B;&#xFF08;&#x70BA;&#x81EA;&#x5DF1;&#xFF09;&#x8F49;&#x8B8A;&#x6210;&#x5927;&#x611B;&#xFF08;&#x70BA;&#x5225;&#x4EBA;&#xFF09;&#xFF0C;&#x9019;&#x7A2E;&#x4E0D;&#x65B7;&#x91CD;&#x751F;&#x4E26;&#x81EA;&#x6211;&#x512A;&#x5316;&#x7684;&#x904E;&#x7A0B;&#xFF0C;&#x96D6;&#x7136;&#x6709;&#x9EDE;&#x8352;&#x8A95;&#x641E;&#x7B11;&#xFF0C;&#x537B;&#x662F;&#x7B11;&#x4E2D;&#x5E36;&#x6DDA;&#x7684;&#x89F8;&#x52D5;&#x4EBA;&#x5FC3;&#x3002;&#x9019;&#x4E5F;&#x8B93;&#x6211;&#x5011;&#x53CD;&#x601D;&#xFF0C;&#x70BA;&#x4EC0;&#x9EBC;&#x91CD;&#x65B0;&#x6295;&#x80CE;&#x6210;&#x70BA;&#x4EBA;&#x985E;&#x5C31;&#x662F;&#x6700;&#x597D;&#x7684;&#x9078;&#x64C7;&#x5462;&#xFF1F;&#x90A3;&#x662F;&#x4E0D;&#x662F;&#x56E0;&#x70BA;&#x6211;&#x5011;&#x81EA;&#x5DF1;&#x5E36;&#x8457;&#x4EBA;&#x985E;&#x4E2D;&#x5FC3;&#x4E3B;&#x7FA9;&#x7684;&#x60F3;&#x6CD5;&#xFF0C;&#x4EA6;&#x6216;&#x8005;&#x662F;&#x56E0;&#x70BA;&#x4EBA;&#x985E;&#x672C;&#x8EAB;&#x7684;&#x512A;&#x8D8A;&#x611F;&#x4F7F;&#x7136;&#xFF1F;&#x9019;&#x4E5F;&#x5F71;&#x97FF;&#x8457;&#x6211;&#x5011;&#x8A72;&#x5982;&#x4F55;&#x597D;&#x597D;&#x5EA6;&#x904E;&#x6B64;&#x751F;&#x3002;</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe src="https://www.youtube.com/embed/_4DJkOUU648?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe><figcaption>ZARD&#x200A;&#x2014;&#x200A;&#x8CA0;&#x3051;&#x306A;&#x3044;&#x3067;</figcaption></figure><p>&#x300A;&#x91CD;&#x555F;&#x4EBA;&#x751F;&#x300B;&#x7D66;&#x89C0;&#x773E;&#x5E36;&#x4F86;&#x4E86;&#x5F88;&#x591A;&#x7684;&#x601D;&#x8003;&#x548C;&#x611F;&#x52D5;&#x3002;&#x5B83;&#x8B93;&#x4EBA;&#x5011;&#x91CD;&#x65B0;&#x601D;&#x8003;&#x81EA;&#x5DF1;&#x7684;&#x751F;&#x547D;&#x610F;&#x7FA9;&#x548C;&#x50F9;&#x503C;&#xFF0C;&#x8B93;&#x4EBA;&#x5011;&#x610F;&#x8B58;&#x5230;&#x751F;&#x547D;&#x7684;&#x73CD;&#x8CB4;&#x8207;&#x6709;&#x9650;&#x3002;&#x9019;&#x90E8;&#x5F71;&#x96C6;&#x8B93;&#x6211;&#x5011;&#x91CD;&#x65B0;&#x56DE;&#x9867;&#x904E;&#x53BB;&#x7684;&#x6B72;&#x6708;&#xFF0C;&#x56DE;&#x61B6;&#x90A3;&#x4E9B;&#x7F8E;&#x597D;&#x7684;&#x6642;&#x5149;&#xFF0C;&#x540C;&#x6642;&#x4E5F;&#x8B93;&#x4EBA;&#x5011;&#x91CD;&#x65B0;&#x601D;&#x8003;&#x672A;&#x4F86;&#x7684;&#x65B9;&#x5411;&#xFF0C;&#x662F;&#x503C;&#x5F97;&#x4E00;&#x770B;&#x7684;&#x611F;&#x4EBA;&#x4F5C;&#x54C1;&#x3002;</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe src="https://www.youtube.com/embed/B2fPYlGKdXM?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe><figcaption>AI&#x200A;&#x2014;&#x200A;Story</figcaption></figure>]]></content:encoded></item><item><title><![CDATA[製作脆梅的時節 / Make Crispy Plum]]></title><description><![CDATA[製作脆梅一直是我們家重要的儀式，每年我們都會在年初與信義鄉的小農預訂青梅，並以此製作脆梅。]]></description><link>https://blog.cmwang.net/e8-a3-bd-e4-bd-9c-e8-84-86-e6-a2-85-e7-9a-84-e6-99-82-e7-af-80-make-crispy-plum/</link><guid isPermaLink="false">65ba7277b102c4db988584f0</guid><category><![CDATA[Plum]]></category><category><![CDATA[脆梅]]></category><category><![CDATA[Ceremony]]></category><category><![CDATA[Life]]></category><category><![CDATA[Family]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Sun, 16 Apr 2023 15:16:37 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg" medium="image"/><content:encoded><![CDATA[<h3 id="-make-crispy-plum">&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x7684;&#x6642;&#x7BC0; | Make Crispy Plum</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-8ya9rsc0l5ob3ll72cnmnw.jpg" class="kg-image" alt="&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x7684;&#x6642;&#x7BC0; / Make Crispy Plum" loading="lazy" width="1440" height="1440" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-8ya9rsc0l5ob3ll72cnmnw.jpg 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-8ya9rsc0l5ob3ll72cnmnw.jpg 1000w, https://blog.cmwang.net/content/images/max/800/1-8ya9rsc0l5ob3ll72cnmnw.jpg 1440w" sizes="(min-width: 720px) 720px"><figcaption>&#x9752;&#x6885; | green&#xA0;plums</figcaption></figure><img src="https://blog.cmwang.net/content/images/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg" alt="&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x7684;&#x6642;&#x7BC0; / Make Crispy Plum"><p>&#x8FD1;&#x5E74;&#x4F86;&#xFF0C;&#x6E05;&#x660E;&#x7BC0;&#x524D;&#x5F8C;&#x4E00;&#x76F4;&#x662F;&#x6211;&#x5011;&#x5BB6;&#x91CD;&#x8981;&#x7684;&#x5100;&#x5F0F;&#xFF0C;&#x6211;&#x5011;&#x6703;&#x5728;&#x5E74;&#x521D;&#x8207;&#x4FE1;&#x7FA9;&#x9109;&#x7684;&#x5C0F;&#x8FB2;&#x9810;&#x8A02;12&#x516C;&#x65A4;&#x9752;&#x6885;&#xFF0C;&#x4E26;&#x4EE5;&#x6B64;&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x4ECA;&#x5E74;&#x7531;&#x65BC;&#x96E8;&#x91CF;&#x4E0D;&#x8DB3;&#xFF0C;&#x679C;&#x5BE6;&#x76F8;&#x8F03;&#x65BC;&#x5F80;&#x5E74;&#x7A0D;&#x5ACC;&#x4E0D;&#x76E1;&#x4EBA;&#x610F;&#x3002;</p><p>&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x7684;&#x65B9;&#x5F0F;&#x76F8;&#x7576;&#x7C21;&#x55AE;&#xFF0C;&#x4E0D;&#x9700;&#x8981;&#x8907;&#x96DC;&#x7684;&#x5668;&#x6750;&#xFF0C;&#x53EA;&#x9700;&#x82B1;&#x8CBB;&#x4E00;&#x4E9B;&#x6642;&#x9593;&#x8207;&#x8010;&#x5FC3;&#x3002;&#x914D;&#x65B9;&#x975E;&#x5E38;&#x7C21;&#x55AE;&#xFF0C;&#x4EE5;&#x4E00;&#x516C;&#x65A4;&#x9752;&#x6885;&#x3001;100&#x514B;&#x7C97;&#x9E7D;&#x548C;600&#x514B;&#x7802;&#x7CD6;&#x7684;&#x6BD4;&#x4F8B;&#x9032;&#x884C;&#x88FD;&#x4F5C;&#x3002;&#x63A5;&#x4E0B;&#x4F86;&#xFF0C;&#x8ACB;&#x4F9D;&#x7167;&#x4EE5;&#x4E0B;&#x6B65;&#x9A5F;&#x9032;&#x884C;&#xFF1A;</p><ul><li>&#x6E05;&#x6D17;&#xFF1A;&#x53BB;&#x6389;&#x6885;&#x5B50;&#x7684;&#x8482;&#x982D;&#xFF0C;&#x4E00;&#x9846;&#x9846;&#x6311;&#x9664;&#x3002;</li><li>&#x6BBA;&#x9752;&#xFF1A;&#x4F7F;&#x7528;&#x7C97;&#x9E7D;&#x5E6B;&#x52A9;&#x6885;&#x5B50;SPA&#xFF0C;&#x6413;&#x63C9;&#x81F3;&#x5C11;15&#x5206;&#x9418;&#xFF0C;&#x76F4;&#x5230;&#x8868;&#x9762;&#x6FD5;&#x6F64;&#x8B8A;&#x8272;&#x3002;</li><li>&#x6572;&#x6885;&#x5B50;&#xFF1A;&#x7528;&#x69CC;&#x5B50;&#x4E00;&#x9846;&#x9846;&#x6572;&#x6253;&#x81F3;&#x5FAE;&#x88C2;&#xFF0C;&#x5343;&#x842C;&#x5225;&#x6572;&#x788E;&#x4E86;&#x3002;</li><li>&#x6CE1;&#x9E7D;&#x6C34;8&#x5C0F;&#x6642;&#xFF1A;&#x52D9;&#x5FC5;&#x78BA;&#x4FDD;&#x9E7D;&#x6C34;&#x5B8C;&#x5168;&#x8986;&#x84CB;&#x4F4F;&#x6885;&#x5B50;&#x3002;</li><li>&#x63DB;&#x6C34;8&#x5C0F;&#x6642;&#xFF1A;&#x6BCF;&#x4E8C;&#x5230;&#x4E09;&#x5C0F;&#x6642;&#x66F4;&#x63DB;&#x4E00;&#x6B21;&#x6C34;&#x3002;</li><li>&#x52A0;&#x7CD6;&#x6C34;&#xFF1A;&#x6BCF;&#x5929;&#x66F4;&#x63DB;&#x65B0;&#x7684;&#x7CD6;&#x6C34;&#xFF0C;&#x8986;&#x84CB;&#x4F4F;&#x6885;&#x5B50;&#xFF0C;&#x91CD;&#x8907;&#x4E09;&#x5929;&#x3002;&#x63DB;&#x7CD6;&#x6C34;&#x7684;&#x904E;&#x7A0B;&#x9817;&#x70BA;&#x91CD;&#x8981;&#xFF0C;&#x8981;&#x5C0F;&#x5FC3;&#x8B39;&#x614E;&#xFF0C;&#x4EE5;&#x514D;&#x5F71;&#x97FF;&#x53E3;&#x611F;&#x3002;</li><li>&#x53BB;&#x6389;&#x82E6;&#x6F80;&#x7CD6;&#x6C34;&#xFF1A;&#x5C07;&#x6240;&#x6709;&#x7684;&#x82E6;&#x6F80;&#x7CD6;&#x6C34;&#x5012;&#x6389;&#xFF0C;&#x53D6;&#x4EE3;&#x70BA;&#x6700;&#x5F8C;&#x4E00;&#x6B21;&#x7684;&#x7CD6;&#x6C34;&#xFF0C;&#x518D;&#x7B49;&#x5F85;&#x4E09;&#x5929;&#xFF0C;&#x5373;&#x53EF;&#x5B8C;&#x6210;&#x88FD;&#x4F5C;&#x3002;</li></ul><p>&#x6211;&#x611F;&#x6FC0;&#x5BB6;&#x4EBA;&#x70BA;&#x751F;&#x6D3B;&#x5E36;&#x4F86;&#x7684;&#x5100;&#x5F0F;&#x611F;&#xFF0C;&#x9019;&#x7A2E;&#x611F;&#x89BA;&#x8B93;&#x6211;&#x611F;&#x53D7;&#x5230;&#x751F;&#x547D;&#x7684;&#x7F8E;&#x597D;&#x3002;</p><hr><p>The time leading up to and following the Tomb Sweeping Festival has become a significant rite for my family in recent years. We purchase green plums in advance from local farmers in Xinyi Township and use them to create preserved plums. However, due to insufficient rainfall this year, the fruit was slightly less than satisfactory compared to previous years.</p><p>Making preserved plums is a straightforward technique that doesn&#x2019;t call for specialized equipment; rather, it just takes some time and perseverance. One kilogram of green plums, 100 grams of coarse salt, and 600 grams of sugar make up the recipe, which is quite straightforward. Please carry out the actions listed below:</p><ul><li>Wash the plums and remove the stems one by one.</li><li>Blanch the plums by rubbing them with coarse salt for at least 15 minutes until the surface becomes moist and changes color.</li><li>Tap the plums with a hammer one by one until they crack slightly, but do not smash them.</li><li>Soak the plums in saltwater for 8 hours, making sure that the water covers them completely.</li><li>Pour out the syrup and replace it with fresh syrup every 8 hours.</li><li>Repeat step 5 for 3 days until the plums are fully infused with the sugar syrup.</li><li>Drain the plums of any remaining bitter syrup, replace it with the final batch of sugar syrup, and let it sit for another 3 days to complete the process.</li></ul><p>I am grateful to my family for bringing a sense of ceremony into our daily lives. This ritual makes me appreciate the beauty of life.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-_ervpwwjvx3arz_sv_rqcw.jpg" class="kg-image" alt="&#x88FD;&#x4F5C;&#x8106;&#x6885;&#x7684;&#x6642;&#x7BC0; / Make Crispy Plum" loading="lazy" width="1440" height="1440" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-_ervpwwjvx3arz_sv_rqcw.jpg 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-_ervpwwjvx3arz_sv_rqcw.jpg 1000w, https://blog.cmwang.net/content/images/max/800/1-_ervpwwjvx3arz_sv_rqcw.jpg 1440w" sizes="(min-width: 720px) 720px"><figcaption>&#x8106;&#x6885;&#x6210;&#x54C1; | Crispy&#xA0;Plum</figcaption></figure>]]></content:encoded></item><item><title><![CDATA[Nilvana Vision Studio 2.2.0: Heatmap for Annotations]]></title><description><![CDATA[Introducing vision studio 2.2.0 with heatmap for object detection annotations]]></description><link>https://blog.cmwang.net/released-nilvana-vision-studio-2-2-0/</link><guid isPermaLink="false">65ba7277b102c4db988584e9</guid><category><![CDATA[Computer Vision]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Object Detection]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Mon, 10 Apr 2023 02:35:32 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-6gudkrjpaa0p3tqphk00kw.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-6gudkrjpaa0p3tqphk00kw.jpg" alt="Nilvana Vision Studio 2.2.0: Heatmap for Annotations"><p>We are pleased to introduce version 2.2.0 of vision studio, a user-friendly web-based collaborative data annotation, model training, and model evaluation No-code toolkit. You can find more information about <strong>Nilvana&#x2122; vision studio</strong> on the <a href="https://shop.nilvana.ai/products/nilvana-vision-studio?ref=localhost" rel="noopener ugc nofollow noopener">official website</a>.</p><h4 id="heatmap-for-annotations">Heatmap for Annotations</h4><p>In this version, we have added a new feature: heatmap for annotations, which allows you to more effectively visualize the positions of object detection bounding boxes in your dataset and version. The heatmap provides a color-coded representation of the density of annotations, making it easier to identify areas of high or low annotation density. This feature can be particularly useful for evaluating the quality of collaborative annotation efforts and identifying areas where additional annotation may be needed. Overall, the heatmap for annotations provides a powerful tool for improving the accuracy and efficiency of your annotation workflow.</p><h4 id="improvements-and-bug-fixes">Improvements and Bug Fixes</h4><p>We have not been sitting on our hands. In this version, in addition to the new features mentioned above, we also fixed a lot of bugs. These items are fairly trivial and I won&#x2019;t list them here. But yes, we have improved it if you see any differences.</p><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-4nxbz0zkih9jhi69.jpg" alt="Nilvana Vision Studio 2.2.0: Heatmap for Annotations"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[今天你會有好事發生]]></title><description><![CDATA[Today you will have a good day. Jesus spoke to them at once, “Don’t be afraid,” he said. “Take courage! I am here!” (Mark 6:50)]]></description><link>https://blog.cmwang.net/e4-bb-8a-e5-a4-a9-e4-bd-a0-e6-9c-83-e6-9c-89-e5-a5-bd-e4-ba-8b-e7-99-bc-e7-94-9f/</link><guid isPermaLink="false">65ba7277b102c4db988584ea</guid><category><![CDATA[我的出走日記]]></category><category><![CDATA[Myliberationnotes]]></category><category><![CDATA[Feelings]]></category><category><![CDATA[Courage]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Thu, 06 Apr 2023 12:29:10 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-dts8vwjc-loeagf4bnsunw.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-dts8vwjc-loeagf4bnsunw.jpg" alt="&#x4ECA;&#x5929;&#x4F60;&#x6703;&#x6709;&#x597D;&#x4E8B;&#x767C;&#x751F;"><p>Today you will have a good day. Jesus spoke to them at once, &#x201C;Don&#x2019;t be afraid,&#x201D; he said. &#x201C;Take courage! I am here!&#x201D; (Mark 6:50)</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-tmx6ku_lgl2oxumfvarlpw.png" class="kg-image" alt="&#x4ECA;&#x5929;&#x4F60;&#x6703;&#x6709;&#x597D;&#x4E8B;&#x767C;&#x751F;" loading="lazy" width="2000" height="1333" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-tmx6ku_lgl2oxumfvarlpw.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-tmx6ku_lgl2oxumfvarlpw.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-tmx6ku_lgl2oxumfvarlpw.png 1600w, https://blog.cmwang.net/content/images/max/800/1-tmx6ku_lgl2oxumfvarlpw.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>My Liberation Notes</figcaption></figure>]]></content:encoded></item><item><title><![CDATA[Reflections on Five Years in the Company]]></title><description><![CDATA[As I reflect on my five years in this company, I realize how much has happened and how much I have grown…]]></description><link>https://blog.cmwang.net/reflections-on-five-years-in-the-company/</link><guid isPermaLink="false">65ba7277b102c4db988584f1</guid><category><![CDATA[Reflections]]></category><dc:creator><![CDATA[Jamie Wang]]></dc:creator><pubDate>Mon, 27 Mar 2023 14:46:01 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-soyyinqnadusp3aofsthqg-2x.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-soyyinqnadusp3aofsthqg-2x.jpg" alt="Reflections on Five Years in the Company"><p>As I reflect on my five years in this company, I realize how much has happened and how much I have grown. From having a supervisor to being a lone ranger, to forming a small team and eventually founding the Nilvana, time has flown by quickly, and I am left wondering where tomorrow will take me.</p><p>It seems like just yesterday that I started my journey in this company. I remember the excitement of meeting new colleagues, learning new skills, and finding my place in the organization. Over time, I became more confident and began taking on more responsibilities. I was proud of my accomplishments and the impact that I was making.</p><p>However, the road was not always easy. There were times when I faced challenges that made me question my abilities and my decisions. I learned that setbacks and failures are a part of the journey, and they can be a source of growth and resilience.</p><p>One of the most significant moments in my journey was the creation of the Nilvana brand. It was a leap of faith, but I knew that I had a vision that could change the game. With the help of a few dedicated team members, we worked tirelessly to bring the brand to life. Seeing it take off and gain recognition was one of the proudest moments of my career.</p><p>Looking back on my journey, I realize that time truly flies. It seems like just yesterday that I started, but five years have gone by in a blink of an eye. As I prepare to take on new challenges, I am grateful for the experiences and the lessons that I have learned.</p><hr><figure class="kg-card kg-embed-card"><iframe src="https://www.youtube.com/embed/1t8kAbUg4t4?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure>]]></content:encoded></item><item><title><![CDATA[Backing Up a Stellar Data Engineer: Open for New Opportunities in Taipei]]></title><description><![CDATA[I am writing this post to recommend my colleague Jill Hsu for any relevant job opportunities in Taipei.]]></description><link>https://blog.cmwang.net/backing-up-a-stellar-data-engineer-open-for-new-opportunities-in-taipei/</link><guid isPermaLink="false">65ba7277b102c4db988584ef</guid><category><![CDATA[Jobsearch]]></category><category><![CDATA[Taipei]]></category><category><![CDATA[Backend Development]]></category><category><![CDATA[Data Science]]></category><category><![CDATA[Tech Jobs]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Thu, 23 Mar 2023 11:08:10 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-h3-aa9-_smfa7fsgn8kavw.png" medium="image"/><content:encoded><![CDATA[<h3 id="backing-up-a-stellar-engineer-open-for-new-opportunities-in-taipei">Backing Up a Stellar Engineer: Open for New Opportunities in Taipei</h3><img src="https://blog.cmwang.net/content/images/max/800/1-h3-aa9-_smfa7fsgn8kavw.png" alt="Backing Up a Stellar Data Engineer: Open for New Opportunities in Taipei"><p>I am writing this post to recommend my colleague <a href="https://medium.com/u/e76bffbfaa3d?ref=localhost">Jill Hsu</a> for any relevant job opportunities in Taipei. As her teammate in the backend and machine learning data engineering team, I can attest to her outstanding work ethics, attention to detail, and passion for delivering high-quality results.</p><p><a href="https://medium.com/u/e76bffbfaa3d?ref=localhost">Jill Hsu</a> is a highly skilled data engineer with extensive experience in both backend development and machine learning. Her technical knowledge and expertise in backend development, including database management, API design, and server architecture, have been invaluable to our team&#x2019;s success. She has consistently demonstrated her ability to handle complex backend development projects and deliver results in a timely and efficient manner.</p><p>Moreover, <a href="https://medium.com/u/e76bffbfaa3d?ref=localhost">Jill Hsu</a> is a great team player and collaborator. She communicates effectively with her teammates and stakeholders, always willing to share her knowledge and insights to help others achieve their goals. Her positive attitude, proactive approach, and strong work ethic make her an asset to any team.</p><p>As <a href="https://medium.com/u/e76bffbfaa3d?ref=localhost">Jill Hsu</a> is now looking for new job opportunities in Taipei, I highly recommend her for any data engineering or related positions. She is a reliable and dedicated professional who can bring significant value to any organization. I am confident that her skills and experience will make her a valuable addition to any team.</p><p>I believe that she has the potential to excel in any role she takes on and wish her all the best in her career journey.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://takawang.medium.com/the-release-of-vision-studio-2-0-is-scheduled-for-november-a347d4bae86c?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">The release of Vision Studio 2.0.0 is scheduled for November</div><div class="kg-bookmark-description">Support for multiple GPU training is one of the most commonly feature requested, we will incorporate this option in the&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/1-zatxvvtmagb_5hvah3tepq.jpg" alt="Backing Up a Stellar Data Engineer: Open for New Opportunities in Taipei"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Nilvana Vision Studio 2.1.0: Advanced Instance Segmentation Features Now Available]]></title><description><![CDATA[Introducing vision studio 2.1.0 with instance segmentation support and streamlined annotation workflow features.]]></description><link>https://blog.cmwang.net/nilvana-vision-studio-2-1-0-advanced-instance-segmentation-features-now-available/</link><guid isPermaLink="false">65ba7277b102c4db988584e8</guid><category><![CDATA[Computer Vision]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[人工智慧]]></category><category><![CDATA[電腦視覺]]></category><category><![CDATA[Instance Segmentation]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Fri, 17 Mar 2023 07:05:54 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-cxjzei7velztfrloui4njg.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-cxjzei7velztfrloui4njg.jpg" alt="Nilvana Vision Studio 2.1.0: Advanced Instance Segmentation Features Now Available"><p>We are pleased to introduce version 2.1.0 of vision studio, a user-friendly web-based collaborative data annotation, model training, and model evaluation No-code toolkit. You can find more information about <strong>Nilvana&#x2122; vision studio</strong> on the <a href="https://nilvana.ai/?ref=localhost" rel="noopener">official website</a>.</p><hr><h3 id="new-algorithms-and-problem-types">New Algorithms and Problem Types</h3><p>In smart manufacturing, instance segmentation can play a critical role in enhancing quality control and improving productivity. Unlike object detection, instance segmentation can predict the precise boundaries of individual objects and provide a detailed mask and area of each instance, allowing for even more accurate and efficient tracking of components and products within manufacturing processes.</p><p>With this advanced feature, instance segmentation algorithms can detect faulty parts in real-time and enable timely interventions, reducing waste and improving production quality. The technology can also automate tasks such as identifying and counting products for inventory management, streamlining operations and reducing costs. Overall, by leveraging the power of instance segmentation, smart manufacturers can achieve higher levels of efficiency, reduce costs, and ultimately increase profitability by streamlining their operations.</p><h3 id="streamlined-annotation-workflow">Streamlined Annotation Workflow</h3><p>Our toolkit provides a variety of features to speed up and simplify the instance segmentation annotation process. With our <strong>group annotation</strong> feature, users can easily annotate objects that are disconnected or partially occluded, without having to painstakingly annotate each individual pixel. Our <strong>edge detection</strong> <strong>annotation</strong> feature further streamlines the process by automatically detecting object boundaries and generating annotations accordingly. Additionally, our <strong>real-time collaborative annotation</strong> capability allows multiple users to work on the same project simultaneously, increasing efficiency and collaboration. For even greater speed and efficiency, our <strong>intelligent interactive annotation</strong> feature allows users to automatically annotate objects with a single click, powered by advanced machine learning algorithms.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-7l56tn-uxdwhew0xtwewrq.gif" class="kg-image" alt="Nilvana Vision Studio 2.1.0: Advanced Instance Segmentation Features Now Available" loading="lazy" width="1402" height="896" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-7l56tn-uxdwhew0xtwewrq.gif 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-7l56tn-uxdwhew0xtwewrq.gif 1000w, https://blog.cmwang.net/content/images/max/800/1-7l56tn-uxdwhew0xtwewrq.gif 1402w" sizes="(min-width: 720px) 720px"><figcaption>Intelligent interactive annotation</figcaption></figure><h3 id="batch-annotation-made-easy-with-machine-annotation-capabilities">Batch Annotation Made Easy with Machine Annotation Capabilities</h3><p>To further accelerate the annotation process, we also offer machine annotation capabilities, allowing users to batch annotate images using pre-trained or custom-trained models. This can save valuable time and effort, particularly for large datasets or recurring annotation tasks. With these features, our toolkit is the ultimate solution for fast and accurate annotation, improving productivity and allowing users to focus on more important tasks.</p><h3 id="japanese-language-support">Japanese Language Support</h3><p>At Nilvana&#x2122;, we recognize the importance of catering to a diverse range of users and their language preferences. With this in mind, we are excited to announce that Nilvana&#x2122; Vision Studio 2.1.0 now includes Japanese language support in addition to English and Chinese.</p><h3 id="experience-the-power-of-nilvana-vision-studio-today">Experience the Power of Nilvana Vision Studio Today</h3><p>Ready to streamline your annotation workflow, accelerate your model training, and improve your model evaluation with Nilvana&#x2122; Vision Studio? <a href="https://shop.nilvana.ai/pages/book-demo?ref=localhost" rel="noopener">Book a demo</a> today and experience the ultimate solution for fast and accurate annotation without requiring any coding expertise. Our team will guide you through the process and answer any questions you may have. Alternatively, if you would like to discuss your specific business needs and challenges, we would be happy to schedule a consultation to explore how our toolkit can help you achieve your goals. Don&#x2019;t settle for less when it comes to instance segmentation. Choose <strong>Nilvana&#x2122; Vision Studio</strong> and experience the difference for yourself.</p><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-a1och0vbygptckqz.jpg" alt="Nilvana Vision Studio 2.1.0: Advanced Instance Segmentation Features Now Available"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Configuring USB-FS for USB3 Vision Camera]]></title><description><![CDATA[This post explains how to increase the buffer memory for USB-FS devices on Linux systems.]]></description><link>https://blog.cmwang.net/configuring-usb-fs-for-usb3-vision-camera/</link><guid isPermaLink="false">65ba7277b102c4db988584e4</guid><category><![CDATA[Industrial Camera Systems]]></category><category><![CDATA[Embedded Systems]]></category><category><![CDATA[U3v]]></category><category><![CDATA[Computer Vision]]></category><category><![CDATA[Machine Vision System]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Thu, 29 Dec 2022 13:14:24 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-uoy9jp33j7xif2emebtdcg.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-uoy9jp33j7xif2emebtdcg.jpg" alt="Configuring USB-FS for USB3 Vision Camera"><p>This post explains how to increase the buffer memory for USB-FS devices on Linux systems in order to make full use of the imaging hardware&#x2019;s capabilities. By default, USB-FS on Linux systems only allows 16 MB of buffer memory for all USB devices, which may not be sufficient for high-resolution cameras or multiple-camera set ups, resulting in image acquisition issues. To configure USB-FS and increase the buffer memory limit, the following steps should be taken:</p><p>Note that GRUB is for desktop PC architecture. ARM embedded systems use a different bootloader, as GRUB requires a system with a BIOS, and embedded systems do not have one.</p><ol><li>Create the file <code>/etc/rc.local</code> with the command <code>sudo touch /etc/rc.local</code>. This will create the file, allowing it to be edited.</li><li>Change the permissions of the file with the command <code>sudo chmod 744 /etc/rc.local</code>. This will ensure that the file has the correct permissions to be edited.</li><li>Change the buffer memory limit with the command <code>echo 1000 &gt; /sys/module/usbcore/parameters/usbfs_memory_mb</code>. This command will set the memory limit to 1000 MB, which should be enough to prevent image acquisition issues.</li></ol><pre><code class="language-bash">## /etc/rc.local file contents example 
 
#!/bin/sh -e 
echo 1000 &gt; /sys/module/usbcore/parameters/usbfs_memory_mb 
exit 0</code></pre><p>After changing the memory limit, it is important to confirm the changes have been made correctly. This can be done by running the command <code>cat /sys/module/usbcore/parameters/usbfs_memory_mb</code>, which will display the current memory limit. If the limit is still 16 MB, then the changes will need to be made again. Additionally, further information about USB-FS on Linux can be found in the following sources:</p><ul><li><a href="https://www.flir.asia/support-center/iis/machine-vision/application-note/understanding-usbfs-on-linux/?ref=localhost" rel="noopener">Understanding USBFS on Linux</a></li><li><a href="https://importgeek.wordpress.com/2017/02/26/increase-usbfs-memory-limit-in-ubuntu/?ref=localhost" rel="noopener">Increase USBFS Memory Limit in Ubuntu</a></li><li><a href="https://forums.developer.nvidia.com/t/change-kernel-cmdline-by-edit-etc-default-grub-failed/159831/2?ref=localhost" rel="noopener">Change Kernel Cmdline by Edit /etc/default/grub Failed</a></li></ul>]]></content:encoded></item><item><title><![CDATA[Released Nilvana Vision Studio 2.0.0]]></title><description><![CDATA[We are pleased to introduce version 2.0.0 of vision studio. We hope you enjoy this major update!]]></description><link>https://blog.cmwang.net/released-nilvana-vision-studio-2-0-0/</link><guid isPermaLink="false">65ba7277b102c4db988584e7</guid><category><![CDATA[Computer Vision]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[人工智慧]]></category><category><![CDATA[電腦視覺]]></category><category><![CDATA[Object Detection]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Wed, 14 Dec 2022 03:53:02 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-w0twjy8xwzitaaxltn4jbw.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-w0twjy8xwzitaaxltn4jbw.jpg" alt="Released Nilvana Vision Studio 2.0.0"><p>We are pleased to introduce version 2.0.0 of vision studio, a user-friendly web-based collaborative data annotation, model training, and model evaluation No-code toolkit. You can find more information about <strong>Nilvana&#x2122; vision studio</strong> on the <a href="https://shop.nilvana.ai/products/nilvana-vision-studio?ref=localhost" rel="noopener ugc nofollow noopener">official website</a>.</p><hr><h4 id="new-algorithms-and-network-architectures"><strong>New Algorithms and Network Architectures</strong></h4><p>In this new version, we revised the object detection problem&#x2019;s algorithms and network architectures. Researchers have recently proposed a lot of updated, modern operators and tricks, which we have adopted to improve our present implementations. We additionally allow multiple GPU training for the object detection problem. We think you&#x2019;ll like these changes.</p><p>In response to requests from numerous clients, we have also included a quicker and more compact network design for image classification problem in this release. We expect that more cases will benefit from these changes.</p><h4 id="redesign-dataset-version-pages">Redesign Dataset Version Pages</h4><p>In previous versions, you could only view the health of the original dataset. We have redesigned our data set version pages from scratch, now you can also see the data health in different versions of the data set, in addition to information such as image size and statistic charts. These improvements definitely help you understand your data and get higher quality models.</p><h4 id="more-pre-trained-models">More Pre-trained Models</h4><p>We&#x2019;re always trying to make the process of labeling your data easier, faster and more fun. And now we&#x2019;ve made it even easier to get started by adding more pre-trained models.</p><h4 id="improvements-and-bug-fixes">Improvements and Bug Fixes</h4><p>We have not been sitting on our hands. In this version, in addition to the new features mentioned above, we also fixed a lot of bugs. These items are fairly trivial and I won&#x2019;t list them here. But yes, we have improved it if you see any differences.</p><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener noopener noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener noopener noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-ct3mfzsecscczlfx.jpg" alt="Released Nilvana Vision Studio 2.0.0"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[How to install People Counting Toolkit on your Jetson devices]]></title><description><![CDATA[The installation procedure is quite simple — bash <(curl -fsSL https://links.nilvana.ai/get-pc)]]></description><link>https://blog.cmwang.net/how-to-install-people-counting-toolkit-on-your-jetson-devices/</link><guid isPermaLink="false">65ba7277b102c4db988584eb</guid><category><![CDATA[Computer Vision]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Deep Learning]]></category><category><![CDATA[AI]]></category><category><![CDATA[Jetson Nano]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Wed, 28 Sep 2022 01:13:22 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-2zavqgypzo5yujkr_uzflq.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-2zavqgypzo5yujkr_uzflq.jpg" alt="How to install People Counting Toolkit on your Jetson devices"><p><strong>People Counting Toolkit</strong> is a commercial product of Nilvana&#xAE; AI. The installation procedure is quite simple. You must first request a software activation code from us, then ensure that your device satisfies the requirements listed below:</p><ul><li>Jetpack 4.6.x installed</li><li>At least 15GB free space left</li></ul><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://shop.nilvana.ai/products/people-counting-toolkit?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">People Counting Toolkit</div><div class="kg-bookmark-description">Why you need people counting system? Successful site selection is one of the core competencies of a brand. Real-time&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-yx8vmnhogjwmvgpa.jpg" alt="How to install People Counting Toolkit on your Jetson devices"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://shop.nilvana.ai/products/atom-nx-industrial?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Atom NX Industrial</div><div class="kg-bookmark-description">Rapid and stable field inference with fast integration. Equipped with NVIDIA&#xAE; Jetson Xavier&#x2122; NX. All-in-One hardware&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-ckzdtl2pgf-s7nj8.jpg" alt="How to install People Counting Toolkit on your Jetson devices"></div></a></figure><!--kg-card-end: html--><p>Open the terminal and enter the following command:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-hqzoxv_3vnv9ek_glmus5w.png" class="kg-image" alt="How to install People Counting Toolkit on your Jetson devices" loading="lazy" width="1114" height="390" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-hqzoxv_3vnv9ek_glmus5w.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-hqzoxv_3vnv9ek_glmus5w.png 1000w, https://blog.cmwang.net/content/images/max/800/1-hqzoxv_3vnv9ek_glmus5w.png 1114w" sizes="(min-width: 720px) 720px"><figcaption>bash &lt;(curl -fsSL <a href="https://links.nilvana.ai/get-pc%29?ref=localhost" data-href="https://links.nilvana.ai/get-pc)" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://links.nilvana.ai/get-pc)</a></figcaption></figure><p>If your system doesn&#x2019;t have curl, you can install it like this:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-odmq_raf3jb083mw4rmxeq.png" class="kg-image" alt="How to install People Counting Toolkit on your Jetson devices" loading="lazy" width="1130" height="390" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-odmq_raf3jb083mw4rmxeq.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-odmq_raf3jb083mw4rmxeq.png 1000w, https://blog.cmwang.net/content/images/max/800/1-odmq_raf3jb083mw4rmxeq.png 1130w" sizes="(min-width: 720px) 720px"><figcaption>sudo apt-get update &amp;&amp; sudo apt-get install -y&#xA0;curl</figcaption></figure><p>This toolkit is implemented as a container-based micro-services, so you don&#x2019;t need to be an expert in Docker to utilize it&#x200A;&#x2014;&#x200A;we&#x2019;ll take care of the rest.</p><p>We don&#x2019;t currently provide support for Jetpack 5.x, but if you have this or other platform needs, do not hesitate to contact us.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/nilvana-ai/people-counting-installer?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - nilvana-ai/people-counting-installer: People counting toolkit installer</div><div class="kg-bookmark-description">People Counting Toolkit is a commercial product of Nilvana&#x2122; AI, please refer to the official website for more about&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-if_vsqtz28zh7zyo.png" alt="How to install People Counting Toolkit on your Jetson devices"></div></a></figure><!--kg-card-end: html--><hr><p>Nilvana&#xAE; has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana&#xAE; provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-pwhpl116x_cl6sk5.jpg" alt="How to install People Counting Toolkit on your Jetson devices"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Meet the Nilvana People Counting Toolkit]]></title><description><![CDATA[We are excited to introduce the people counting toolkit, a user-friendly web-based people counting solution that is driven by AI.]]></description><link>https://blog.cmwang.net/meet-the-nilvana-people-counting-toolkit/</link><guid isPermaLink="false">65ba7277b102c4db988584e6</guid><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Computer Vision]]></category><category><![CDATA[Deep Learning]]></category><category><![CDATA[People Counting Camera]]></category><category><![CDATA[People Counter]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Tue, 27 Sep 2022 02:29:16 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-mzr-hs48-ttbp0ynjl3yuw.jpg" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-ilnz8uccxa5rgfl2hfiu9w.jpg" class="kg-image" alt="Meet the Nilvana People Counting Toolkit" loading="lazy" width="1620" height="900" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-ilnz8uccxa5rgfl2hfiu9w.jpg 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-ilnz8uccxa5rgfl2hfiu9w.jpg 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-ilnz8uccxa5rgfl2hfiu9w.jpg 1600w, https://blog.cmwang.net/content/images/max/800/1-ilnz8uccxa5rgfl2hfiu9w.jpg 1620w" sizes="(min-width: 720px) 720px"><figcaption>Introduce people counting&#xA0;toolkit</figcaption></figure><img src="https://blog.cmwang.net/content/images/max/800/1-mzr-hs48-ttbp0ynjl3yuw.jpg" alt="Meet the Nilvana People Counting Toolkit"><p>We are excited to introduce the <strong>people counting toolkit</strong>, a user-friendly web-based people counting solution that is driven by AI. You can find more information about Nilvana&#xAE; people counting toolkit on the <a href="https://shop.nilvana.ai/products/people-counting-toolkit?ref=localhost" rel="noopener">official website</a>.</p><h3 id="why-you-need-people-counting-system">Why you need people counting system?</h3><p>Here are three crucial ideas to help you grow your company using a people counting system.</p><ul><li><strong>Assistance in choosing the best site</strong></li></ul><p>Successful site selection is one of the core competencies of a brand. Real-time monitoring of outdoor traffic data, evaluation of area popularity, and analysis of customer walking paths to help reduce the risk of decision making. If you have customers visiting your business location, it&#x2019;s essential to understand their movement patterns.</p><ul><li><strong>Know the traffic of your customers</strong></li></ul><p>This web-based people counting system is used to accurately count the number of people passing a specified point. By analyzing these results, you can easily control the number of visitors to your store and plan your promotion strategies accordingly. Assembling the counting data from multiple periods and routes to make it easier to observe the variations between the routes. Popular weekly peak (hours) analysis can be used to adjust management strategy and application by assessing total flow data and sales.</p><ul><li><strong>Proper staffing</strong></li></ul><p>Our AI-powered web-based people counting system makes it easy to know how many customers are in your store at any given moment of the day. When you have a clear view of how busy your store is, it&#x2019;s easier to make decisions about staffing and cost-control, as well as optimize your customer experience.</p><h3 id="why-do-you-choose-us">Why do you choose us?</h3><p>We are a team of hard-working and passionate developers who care deeply about the products we design. We have many years of related experience in the IoT and AI area, and all our systems and software interfaces have been carefully developed by us. We have sufficient research and development capabilities and experiences, not only in offering packaged products but also customization of different AI models or software functions according to your needs.</p><hr><p>Nilvana&#xAE; has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana&#xAE; provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.tw/products/people-counting-toolkit?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">People Counting Toolkit</div><div class="kg-bookmark-description">&#x9078;&#x5740;&#x6210;&#x529F;&#xFF0C;&#x662F;&#x54C1;&#x724C;&#x7684;&#x6838;&#x5FC3;&#x7AF6;&#x722D;&#x529B;&#x4E4B;&#x4E00;&#x3002;&#x5373;&#x6642;&#x76E3;&#x63A7;&#x6236;&#x5916;&#x5BA2;&#x6D41;&#x6578;&#x64DA;&#x3001;&#x8A55;&#x4F30;&#x5340;&#x57DF;&#x71B1;&#x5EA6;&#x3001;&#x5206;&#x6790;&#x9867;&#x5BA2;&#x6B65;&#x884C;&#x8DEF;&#x5F91;&#xFF0C;&#x4EE5;&#x5229;&#x964D;&#x4F4E;&#x6C7A;&#x7B56;&#x7684;&#x98A8;&#x96AA;&#x3002; &#x5982;&#x679C;&#x4F60;&#x64C1;&#x6709;&#x5BA2;&#x6236;&#x4F86;&#x8A2A;&#x4F60;&#x7684;&#x5834;&#x6240;&#x7684;&#x696D;&#x52D9;&#xFF0C;&#x4E86;&#x89E3;&#x4ED6;&#x5011;&#x7684;&#x884C;&#x70BA;&#x81F3;&#x95DC;&#x91CD;&#x8981;&#x3002; &#x6536;&#x96C6;&#x548C;&#x5206;&#x6790;&#x4EBA;&#x6D41;&#x6578;&#x64DA;&#x53EF;&#x4EE5;&#x8B93;&#x4F60;&#x77E5;&#x9053;&#x5BA2;&#x6236;&#x53EF;&#x80FD;&#x6703;&#x5728;&#x4F55;&#x6642;&#x4F86;&#x5230;&#x4F60;&#x7684;&#x5546;&#x5E97;&#x6216;&#x5834;&#x6240;&#x3002;&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-phntgfhdsfnawiuo.jpg" alt="Meet the Nilvana People Counting Toolkit"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-fmbc05n1vnuyorog.jpg" alt="Meet the Nilvana People Counting Toolkit"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Make your own pig counter]]></title><description><![CDATA[In this article, I’ll show you how to create a basic pig counter using vision studio and inference runtime.]]></description><link>https://blog.cmwang.net/make-your-own-pig-counter/</link><guid isPermaLink="false">65ba7277b102c4db988584df</guid><category><![CDATA[Object Detection]]></category><category><![CDATA[Object Tracking]]></category><category><![CDATA[Computer Vision]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Deep Learning]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Thu, 15 Sep 2022 08:01:11 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-g2dy2xyioybolnrapwaxvg.jpg" medium="image"/><content:encoded><![CDATA[<h3 id="make-your-own-pig-counter-">Make your own pig counter &#x1F437;</h3><img src="https://blog.cmwang.net/content/images/max/800/1-g2dy2xyioybolnrapwaxvg.jpg" alt="Make your own pig counter"><p>&#x201C;Pork meat is a good source of proteins since their quality is high biological value and has all required amino-acids to promote simple absorption by the organism,&#x201D; says nutritionist Magnolia Escobar. Its meat has a high degree of or rate of digestibility, which can reach 92%, and is more similar to white meat than red meat. But how does artificial intelligence relate to the pig <strong>breeding industry</strong>? Can artificial intelligence and computer vision boost the breeding industry&#x2019;s output? We&#x2019;ll put on a quick demonstration in this post. No offense to vegans, but this is only an illustration. We all love Peppa Pig &#x1F43D;.</p><p>In this article, I&#x2019;ll show you how to create a basic pig counter using <a href="https://shop.nilvana.ai/products/nilvana-vision-studio?ref=localhost" rel="noopener">vision studio</a> and <a href="https://shop.nilvana.ai/products/nilvana-vision-inference-runtime?ref=localhost" rel="noopener">inference runtime</a>. You must first realize that <strong>object detection</strong> and <strong>object tracking</strong> are two distinct ideas. Finding the class and coordinates of objects in a given frame is the goal of object detection, whereas associating objects in a series of frames is the goal of object tracking. Our toolkits can assist you in solving the object detection issue, and the OpenCV library has at least seven pre-made object tracking methods that you can employ as necessary.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.opencv.org/4.6.0/d2/d0a/tutorial_introduction_to_tracker.html?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">OpenCV: Introduction to OpenCV Tracker</div><div class="kg-bookmark-description">In this tutorial you will learn how to Create a tracker object. Use the roi Selector function to select a ROI from a&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-rcm5nzhymkic4psy.png" alt="Make your own pig counter"></div></a></figure><!--kg-card-end: html--><p>To build a pig detection model, we must first collect photos of pigs for labeling. We can find the labeled photos of pigs from this paper&#x200A;&#x2014;&#x200A;<a href="https://arxiv.org/abs/2111.10971?ref=localhost" rel="noopener">Tracking Grow-Finish Pigs Across Large Pens Using Multiple Cameras</a>. Sincere thanks to The <a href="https://ansc.illinois.edu/about/facilities/imported-swine-research-laboratory?ref=localhost" rel="noopener">Imported Swine Research Laboratory</a> (ISRL). Then we can import the dataset into vision studio for model creation.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://drive.google.com/drive/folders/1E2wW2aRENgy_TqlzfICn58ahbTHVIaK6?usp=sharing&amp;ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">ISRL Multi-Camera Tracking Dataset - Google Drive</div><div class="kg-bookmark-description">Edit description</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-akzefkxu7-8d39iz.png" alt="Make your own pig counter"></div></a></figure><!--kg-card-end: html--><hr><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-dpurpw5awev7ab7gzs4-ta.png" class="kg-image" alt="Make your own pig counter" loading="lazy" width="1427" height="808" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-dpurpw5awev7ab7gzs4-ta.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-dpurpw5awev7ab7gzs4-ta.png 1000w, https://blog.cmwang.net/content/images/max/800/1-dpurpw5awev7ab7gzs4-ta.png 1427w" sizes="(min-width: 720px) 720px"><figcaption>ISRL datasets in vision&#xA0;studio.</figcaption></figure><p>You may use the <a href="https://github.com/nilvana-ai/nvir-mask-demo/blob/main/video.py?ref=localhost" rel="noopener"><strong>nvir-mask-demo</strong> repository</a> we previously provided to infer the video once you have finished training the model and establishing the inference endpoint. To incorporate object tracking into your pipeline, you simply need to make a minor modification. In this case, I opt for Kernelized Correlation Filters (KCF), which can consider both speed and accuracy. You can use different algorithms depending on your particular circumstances. The list of pseudo-code is shown below.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-_35nc1s54zmdws9znulioq.png" class="kg-image" alt="Make your own pig counter" loading="lazy" width="1285" height="754" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-_35nc1s54zmdws9znulioq.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-_35nc1s54zmdws9znulioq.png 1000w, https://blog.cmwang.net/content/images/max/800/1-_35nc1s54zmdws9znulioq.png 1285w" sizes="(min-width: 720px) 720px"><figcaption>Pseudo code of object&#xA0;tracking</figcaption></figure><p>With this pipeline, you only need to count the pigs that cross a <strong>ROI line</strong> in order to calculate the number. Here is a short demonstration video we created. The original author is the rightful owner of the video. I hope you enjoy this demo.</p><figure class="kg-card kg-embed-card"><iframe src="https://www.youtube.com/embed/v0O3NPUery4?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><blockquote>Pigs are highly intelligent, social animals!<br><br>The study &#x201C;<a href="https://arxiv.org/abs/2111.10971?ref=localhost" rel="noopener">Tracking Grow-Finish Pigs Across Large Pens Using Multiple Cameras</a>&#x201D; indicated how socially active pigs are. Quick social contacts lead to <strong>identity shifts</strong>. These are the tracking challenges. Difficulties in detection: Pigs gather to stay warm, which might lead to <strong>occlusion</strong>.</blockquote><p>Therefore, today&#x2019;s demonstration is only for educational purposes; further thought and experimental planning are required to create a reliable pig counter. Please don&#x2019;t hesitate to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener">get in touch with us</a> so we can assist you in building your own solution.</p><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-vcyzxuvuo4tg_4_m.jpg" alt="Make your own pig counter"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://shop.nilvana.ai/products/nilvana-vision-studio?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Nilvana&#x2122; Vision Studio</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-yekycoi5fyp_lsjs.png" alt="Make your own pig counter"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://shop.nilvana.ai/products/nilvana-vision-inference-runtime?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Nilvana&#x2122; Vision Inference Runtime</div><div class="kg-bookmark-description">Aside from light-weighting the model and reducing resource requirements on the edge devices, it is also optimized for&#x2026;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-vvnuailsg9aqw2xr.jpg" alt="Make your own pig counter"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Object Detection from the Video Taken by Drone]]></title><description><![CDATA[Nilvana™ Vision Studio has an intuitive web interface that makes it easy to merge annotation data or categories from different datasets.]]></description><link>https://blog.cmwang.net/object-detection-from-the-video-taken-by-drone/</link><guid isPermaLink="false">65ba7277b102c4db988584e1</guid><category><![CDATA[Drones]]></category><category><![CDATA[Object Detection]]></category><category><![CDATA[Computer Vision]]></category><category><![CDATA[Deep Learning]]></category><category><![CDATA[Artificial Intelligence]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Tue, 13 Sep 2022 01:46:48 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-4hcxr7y6b8vdvqo31il38g.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.cmwang.net/content/images/max/800/1-4hcxr7y6b8vdvqo31il38g.jpg" alt="Object Detection from the Video Taken by Drone"><p>In the <a href="https://link.medium.com/0pZ5J3tCftb?ref=localhost" rel="noopener"><strong>last article</strong></a> from <a href="https://medium.com/hello-nilvana?ref=localhost">hello nilvana</a>, we learned how to import the <a href="http://aiskyeye.com/?ref=localhost" rel="noopener">VisDrone dataset</a> into Nilvana<strong>&#x2122;</strong> Vision Studio. It&#x2019;s not that difficult, just follow the instructions or ask us for help. If you have not read it yet, you definitely have to!</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://link.medium.com/0pZ5J3tCftb?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">VisDrone Datasets - Nilavna Vision Studio</div><div class="kg-bookmark-description">&#x4ECA;&#x65E5;&#x8981;&#x5206;&#x4EAB;&#x7684;&#x662F;&#xFF0C;&#x5982;&#x4F55;&#x5C07;&#x76EE;&#x524D; VisDrone &#x7684;&#x7167;&#x7247;&#x8CC7;&#x6599;&#x96C6;&#x900F;&#x904E; Nilvana&#x2122; Vision Studio &#x9032;&#x884C;&#x532F;&#x5165;&#xFF0C;&#x65B9;&#x4FBF;&#x65E5;&#x5F8C;&#x9032;&#x884C;&#x6A21;&#x578B;&#x7684;&#x8A13;&#x7DF4;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-worej9bweqrri1bg.png" alt="Object Detection from the Video Taken by Drone"></div></a></figure><!--kg-card-end: html--><p>As you can see in the Vision Studio screenshots below, you can clearly see the 10 categories annotated in the images. Some time ago I found a beautiful video&#x200A;&#x2014;&#x200A;<a href="https://youtu.be/yXEb0fWLJIY?ref=localhost" rel="noopener"><strong>World&#x2019;s longest drone fpv one shot</strong></a> made by <a href="https://newstepmedia.net/?ref=localhost" rel="noopener">New Step Media</a> on Youtube. I found that there are a lot of indoor scenes that are very suitable for adding the COCO dataset based on the visdrone dataset, so I used this combined dataset to train a object detector. In case you didn&#x2019;t already know, Nilvana<strong>&#x2122;</strong> Vision Studio has an intuitive web interface that makes it easy to <strong>merge annotation data</strong> or <strong>categories</strong> from different datasets with a few mouse clicks.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://blog.cmwang.net/content/images/max/1000/1-hsvqcqt8rvoqfztapf_yra.png" width="1756" height="938" loading="lazy" alt="Object Detection from the Video Taken by Drone" srcset="https://blog.cmwang.net/content/images/size/w600/max/1000/1-hsvqcqt8rvoqfztapf_yra.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/1000/1-hsvqcqt8rvoqfztapf_yra.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/1000/1-hsvqcqt8rvoqfztapf_yra.png 1600w, https://blog.cmwang.net/content/images/max/1000/1-hsvqcqt8rvoqfztapf_yra.png 1756w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="https://blog.cmwang.net/content/images/max/400/1-qhif2slonafquakcfivdwg.png" width="619" height="907" loading="lazy" alt="Object Detection from the Video Taken by Drone" srcset="https://blog.cmwang.net/content/images/size/w600/max/400/1-qhif2slonafquakcfivdwg.png 600w, https://blog.cmwang.net/content/images/max/400/1-qhif2slonafquakcfivdwg.png 619w"></div></div></div><figcaption>Visdrone dataset on Nilvana<strong class="markup--strong markup--figure-strong">&#x2122;</strong> Vision&#xA0;Studio</figcaption></figure><p>You can watch the finished video below. Kudos to <a href="https://newstepmedia.net/?ref=localhost" rel="noopener">New Step Media</a> for creating such a stunning aerial video. Ownership of the original video belongs to <a href="https://newstepmedia.net/?ref=localhost" rel="noopener">New Step Media</a>.</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe src="https://www.youtube.com/embed/-sPxNKfXasU?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe><figcaption>Drone video object detection</figcaption></figure><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://shop.nilvana.ai/products/nilvana-vision-studio?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Nilvana&#x2122; Vision Studio</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-t1p4i956ywoiisku.png" alt="Object Detection from the Video Taken by Drone"></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-axl713cxhhq1guco.jpg" alt="Object Detection from the Video Taken by Drone"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Object detection on a 360 degree camera]]></title><description><![CDATA[As long as you use the same camera to collect photos and perform model inference, you don’t need to care about the type of cameras.]]></description><link>https://blog.cmwang.net/object-detection-on-a-360-degree-camera/</link><guid isPermaLink="false">65ba7277b102c4db988584e0</guid><category><![CDATA[Object Tracking]]></category><category><![CDATA[Object Detection]]></category><category><![CDATA[Computer Vision]]></category><category><![CDATA[Deep Learning]]></category><category><![CDATA[Artificial Intelligence]]></category><dc:creator><![CDATA[Taka Wang]]></dc:creator><pubDate>Wed, 07 Sep 2022 02:52:06 GMT</pubDate><media:content url="https://blog.cmwang.net/content/images/max/800/1-akdt9gxneokjpcdchodnoq.jpg" medium="image"/><content:encoded><![CDATA[<h3 id="object-detection-on-a-360-degree-camera">Object Detection on a 360 degree camera</h3><img src="https://blog.cmwang.net/content/images/max/800/1-akdt9gxneokjpcdchodnoq.jpg" alt="Object detection on a 360 degree camera"><p>We get this question a lot from customers: &#x201C;What kind of cameras should I acquire?&#x201D; Is it possible to detect objects while using a GoPro or other 360-degree camera with <strong>Nilvana&#x2122; vision studio</strong>? The simple answer is that as long as you use the same camera to collect photos and the same device to perform model inference, you don&#x2019;t need to care about the type of cameras you use.</p><p>Due to the necessity of traveling throughout Taiwan, our colleague Sam Li just bought the <a href="https://www.insta360.com/fr/product/insta360-oners/1inch-360?ref=localhost" rel="noopener">Insta360 One RS 1-inch</a>, the company&#x2019;s first 360 camera with two 1-inch CMOS sensors. I think that will result in extremely good image quality performance, we wish him a safe journey.</p><figure class="kg-card kg-image-card"><img src="https://blog.cmwang.net/content/images/max/800/1-fuokuvzhf7ec5jt0ajqjna.gif" class="kg-image" alt="Object detection on a 360 degree camera" loading="lazy" width="638" height="385" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-fuokuvzhf7ec5jt0ajqjna.gif 600w, https://blog.cmwang.net/content/images/max/800/1-fuokuvzhf7ec5jt0ajqjna.gif 638w"></figure><p>Sam really used this camera to gather a lot of real road vehicle condition videos for the vehicle counting toolkit that will be released next month, so keep an eye out for that.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="https://blog.cmwang.net/content/images/max/600/1-mhtfv3zohrxoddkrw19rdq.jpg" width="2000" height="1365" loading="lazy" alt="Object detection on a 360 degree camera" srcset="https://blog.cmwang.net/content/images/size/w600/max/600/1-mhtfv3zohrxoddkrw19rdq.jpg 600w, https://blog.cmwang.net/content/images/size/w1000/max/600/1-mhtfv3zohrxoddkrw19rdq.jpg 1000w, https://blog.cmwang.net/content/images/size/w1600/max/600/1-mhtfv3zohrxoddkrw19rdq.jpg 1600w, https://blog.cmwang.net/content/images/size/w2400/max/600/1-mhtfv3zohrxoddkrw19rdq.jpg 2400w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="https://blog.cmwang.net/content/images/max/800/1-ker9jficq_gl5ylppcfx0q.png" width="1446" height="813" loading="lazy" alt="Object detection on a 360 degree camera" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-ker9jficq_gl5ylppcfx0q.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-ker9jficq_gl5ylppcfx0q.png 1000w, https://blog.cmwang.net/content/images/max/800/1-ker9jficq_gl5ylppcfx0q.png 1446w" sizes="(min-width: 720px) 720px"></div></div></div><figcaption>Vehicle Counting Toolkit is coming&#xA0;soon!!</figcaption></figure><p>Finally, a video of the actual inference of the insta360 video is presented for your reference. It would be great to see more compelling application cases on a 360-degree camera.</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe src="https://www.youtube.com/embed/wi_HJ9aobJQ?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe><figcaption>Object detection in action &#x1F680;</figcaption></figure><hr><p>Nilvana<strong>&#x2122;</strong> has developed <strong>Vision Studio</strong> and <strong>Vision Inference Runtime</strong> toolkits, which enable collaborative data annotation, model creation, and rapid inference without AI expertise.</p><p>Nilvana<strong>&#x2122;</strong> provides a <a href="https://shop.nilvana.ai/pages/our-services?ref=localhost" rel="noopener ugc nofollow noopener">wide range of services</a> from consulting and model creation to the development of AI-based applications. Feel free to <a href="https://shop.nilvana.ai/pages/contact-us?ref=localhost" rel="noopener ugc nofollow noopener">contact us</a> for any inquiries.</p><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana&#x2122;, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, &#x4EBA;&#x5DE5;&#x667A;&#x6167;&#xFF0C;&#x5DE5;&#x4F5C;&#x7AD9;&#xFF0C;&#x7269;&#x806F;&#x7DB2;&#xFF0C;&#x908A;&#x7DE3;&#x904B;&#x7B97;&#xFF0C;&#x908A;&#x7DE3;&#x88DD;&#x7F6E;&#x3002;</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-flo4dgj3qprtljo6.jpg" alt="Object detection on a 360 degree camera"></div></a></figure><!--kg-card-end: html-->]]></content:encoded></item></channel></rss>