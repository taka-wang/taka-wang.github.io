<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Deploying models through Nilvana Vision Inference Runtime</title>
    <link rel="stylesheet" href="/assets/built/screen.css?v=69d004e056">

    <meta name="description" content="Nilvana Vision Inference Runtime (推論套件)是我們針對不同平台模型部署提出的解決方案，你可以輕鬆的將 Nilvana Vision Studio 產出的模型透過這個套件部署到 x86 或者 Jetson 平台上。https://nilvana.tw/">
    <link rel="icon" href="https://blog.cmwang.net/content/images/size/w256h256/2024/01/2-removebg-preview.png" type="image/png">
    <link rel="canonical" href="https://blog.cmwang.net/e9-80-8f-e9-81-8e-nilvana-vision-inference-runtime-e9-83-a8-e7-bd-b2-e6-a8-a1-e5-9e-8b/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Liberation Notes">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Deploying models through Nilvana Vision Inference Runtime">
    <meta property="og:description" content="Using Nilvana Vision Inference Runtime (inference engine), you can easily deploy your models to x86 or Jetson platforms.">
    <meta property="og:url" content="https://blog.cmwang.net/e9-80-8f-e9-81-8e-nilvana-vision-inference-runtime-e9-83-a8-e7-bd-b2-e6-a8-a1-e5-9e-8b/">
    <meta property="og:image" content="https://blog.cmwang.net/content/images/v2/resize:fit:667/1-u6xc7wr939zohyws2_7okg.png">
    <meta property="article:published_time" content="2022-04-25T10:59:01.000Z">
    <meta property="article:modified_time" content="2022-04-25T10:59:01.000Z">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Artificail Intelligence">
    <meta property="article:tag" content="Computer Vision">
    
    <meta property="article:publisher" content="https://www.facebook.com/ghost">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Deploying models through Nilvana Vision Inference Runtime">
    <meta name="twitter:description" content="Using Nilvana Vision Inference Runtime (inference engine), you can easily deploy your models to x86 or Jetson platforms.">
    <meta name="twitter:url" content="https://blog.cmwang.net/e9-80-8f-e9-81-8e-nilvana-vision-inference-runtime-e9-83-a8-e7-bd-b2-e6-a8-a1-e5-9e-8b/">
    <meta name="twitter:image" content="https://blog.cmwang.net/content/images/v2/resize:fit:667/1-u6xc7wr939zohyws2_7okg.png">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Taka Wang">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="AI, Artificail Intelligence, Computer Vision">
    <meta name="twitter:site" content="@ghost">
    <meta property="og:image:width" content="667">
    <meta property="og:image:height" content="683">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Liberation Notes",
        "url": "https://blog.cmwang.net/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://blog.cmwang.net/content/images/size/w256h256/2024/01/2-removebg-preview.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Taka Wang",
        "image": {
            "@type": "ImageObject",
            "url": "https://blog.cmwang.net/content/images/v2/resize:fill:144:144/1-mzehvowngfwyye2pswx_vw.png",
            "width": 144,
            "height": 144
        },
        "url": "https://blog.cmwang.net/author/takawang/",
        "sameAs": []
    },
    "headline": "Deploying models through Nilvana Vision Inference Runtime",
    "url": "https://blog.cmwang.net/e9-80-8f-e9-81-8e-nilvana-vision-inference-runtime-e9-83-a8-e7-bd-b2-e6-a8-a1-e5-9e-8b/",
    "datePublished": "2022-04-25T10:59:01.000Z",
    "dateModified": "2022-04-25T10:59:01.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://blog.cmwang.net/content/images/max/800/1-u6xc7wr939zohyws2_7okg.png",
        "width": 667,
        "height": 683
    },
    "keywords": "AI, Artificail Intelligence, Computer Vision",
    "description": "Using Nilvana Vision Inference Runtime (inference engine), you can easily deploy your models to x86 or Jetson platforms.",
    "mainEntityOfPage": "https://blog.cmwang.net/e9-80-8f-e9-81-8e-nilvana-vision-inference-runtime-e9-83-a8-e7-bd-b2-e6-a8-a1-e5-9e-8b/"
}
    </script>

    <meta name="generator" content="Ghost 5.78">
    <link rel="alternate" type="application/rss+xml" title="Liberation Notes" href="https://blog.cmwang.net/rss/">
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="415aa5f59e59c087cacf652d7b" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/main.css" data-sodo-search="https://blog.cmwang.net/" crossorigin="anonymous"></script>
    
    <link href="https://blog.cmwang.net/webmentions/receive/" rel="webmention">
    <script defer src="/public/cards.min.js?v=69d004e056"></script><style>:root {--ghost-accent-color: #D63484;}</style>
    <link rel="stylesheet" type="text/css" href="/public/cards.min.css?v=69d004e056">
</head>

<body class="post-template tag-ai tag-artificail-intelligence tag-computer-vision tag-hash-medium tag-hash-import-2024-02-01-00-16 is-head-left-logo">
<div class="gh-site">

    <header id="gh-head" class="gh-head gh-outer">
        <div class="gh-head-inner gh-inner">
            <div class="gh-head-brand">
                <div class="gh-head-brand-wrapper">
                    <a class="gh-head-logo" href="https://blog.cmwang.net">
                            Liberation Notes
                    </a>
                </div>
                <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
                <button class="gh-burger"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="https://blog.cmwang.net/">Home</a></li>
    <li class="nav-about"><a href="https://blog.cmwang.net/about/">About</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
            </div>
        </div>
    </header>

    <div class="site-content">
        
<main class="site-main">


    <article class="gh-article post tag-ai tag-artificail-intelligence tag-computer-vision tag-hash-medium tag-hash-import-2024-02-01-00-16">

        <header class="gh-article-header gh-canvas">
            <span class="gh-article-meta">
                By <a href="/author/takawang/">Taka Wang</a>
                    in
                    <a class="gh-article-tag" href="https://blog.cmwang.net/tag/ai/">AI</a>
                —
                <time datetime="2022-04-25">Apr 25, 2022</time>
            </span>

            <h1 class="gh-article-title">Deploying models through Nilvana Vision Inference Runtime</h1>


                <figure class="gh-article-image kg-width-wide">
        <img
            srcset="/content/images/size/w400/max/800/1-u6xc7wr939zohyws2_7okg.png 400w,
                    /content/images/size/w720/max/800/1-u6xc7wr939zohyws2_7okg.png 720w,
                    /content/images/size/w960/max/800/1-u6xc7wr939zohyws2_7okg.png 960w,
                    /content/images/size/w1200/max/800/1-u6xc7wr939zohyws2_7okg.png 1200w,
                    /content/images/size/w2000/max/800/1-u6xc7wr939zohyws2_7okg.png 2000w"
            sizes="(max-width: 1200px) 100vw, 1200px"
            src="/content/images/size/w1200/max/800/1-u6xc7wr939zohyws2_7okg.png"
            alt="Deploying models through Nilvana Vision Inference Runtime"
        >
            <figcaption>Photo by cottonbro from Pexels: <a href="https://www.pexels.com/photo/people-wearing-face-mask-for-protection-3957986/" data-href="https://www.pexels.com/photo/people-wearing-face-mask-for-protection-3957986/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener noopener" target="_blank">https://www.pexels.com/photo/people-wearing-face-mask-for-protection-3957986/</a></figcaption>
    </figure>
        </header>

        <div class="gh-content gh-canvas">
            <h3 id="deploying-models-through-nilvana-vision-inference-runtime">Deploying Models through Nilvana Vision Inference Runtime</h3><p><a href="https://nilvana.tw/products/nilvana-vision-inference-runtime?ref=localhost" rel="noopener">Nilvana Vision Inference Runtime</a> is a software toolkit we have developed for deploying models on different platforms. You can easily deploy models produced by <a href="https://nilvana.tw/products/nilvana%E2%84%A2-vision-studio?ref=localhost" rel="noopener">Nilvana Vision Studio</a> to x86 or Nvidia Jetson platforms through this toolkit. Below, I will demonstrate how to easily create an Endpoint and complete a toy example using less than 10 lines of Python code.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-asbi29m4wxwozhpgd1329w.png" class="kg-image" alt loading="lazy" width="2000" height="1103" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-asbi29m4wxwozhpgd1329w.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-asbi29m4wxwozhpgd1329w.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-asbi29m4wxwozhpgd1329w.png 1600w, https://blog.cmwang.net/content/images/size/w2400/max/800/1-asbi29m4wxwozhpgd1329w.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>After registering for an account, this is the login screen you will see when you open the&nbsp;package.</figcaption></figure><p>After logging in with your account and password, you can quickly create an Endpoint through the “Quick Operation” option.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-9_7sn3hmf7ptuurufxymua.png" class="kg-image" alt loading="lazy" width="2000" height="1441" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-9_7sn3hmf7ptuurufxymua.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-9_7sn3hmf7ptuurufxymua.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-9_7sn3hmf7ptuurufxymua.png 1600w, https://blog.cmwang.net/content/images/max/800/1-9_7sn3hmf7ptuurufxymua.png 2082w" sizes="(min-width: 720px) 720px"><figcaption>Select “Create Endpoint”</figcaption></figure><p>At this point, name your model and upload the compressed ONNX file exported from Nilvana Vision Studio. Currently, we support three types of problems: Object Detection, Image Classification and Segmentation.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-xvz4aywqam29h4abud36-q.png" class="kg-image" alt loading="lazy" width="2000" height="1157" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-xvz4aywqam29h4abud36-q.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-xvz4aywqam29h4abud36-q.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-xvz4aywqam29h4abud36-q.png 1600w, https://blog.cmwang.net/content/images/max/800/1-xvz4aywqam29h4abud36-q.png 2316w" sizes="(min-width: 720px) 720px"><figcaption>Name the model and upload the compressed model&nbsp;file.</figcaption></figure><p>Next, you can choose the minimum threshold and IoU (Intersection over Union) expected for the Endpoint. These values can be adjusted later. If your model has multiple classes, you can also choose to predict only some of them.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-j8doonsb3w60gjdecaebfw.png" class="kg-image" alt loading="lazy" width="2000" height="999" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-j8doonsb3w60gjdecaebfw.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-j8doonsb3w60gjdecaebfw.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-j8doonsb3w60gjdecaebfw.png 1600w, https://blog.cmwang.net/content/images/size/w2400/max/800/1-j8doonsb3w60gjdecaebfw.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Set the threshold and IoU threshold values, which can be fine-tuned later.</figcaption></figure><p>Finally, you can customize a unique identification code with a length of 9 digits, or have the system generate one for you. <strong>Each independent Endpoint uses a unique token</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-i51t_a0tvo54mssjc7avla.png" class="kg-image" alt loading="lazy" width="2000" height="1041" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-i51t_a0tvo54mssjc7avla.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-i51t_a0tvo54mssjc7avla.png 1000w, https://blog.cmwang.net/content/images/size/w1600/max/800/1-i51t_a0tvo54mssjc7avla.png 1600w, https://blog.cmwang.net/content/images/size/w2400/max/800/1-i51t_a0tvo54mssjc7avla.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>You can define the token yourself or have the system generate it. The token cannot be changed&nbsp;later.</figcaption></figure><p>At this point, the system has begun optimizing the model. We perform different optimization actions for different systems. <strong>You only need to wait a few minutes for the Endpoint to become available</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-jqmgxaebesqgoewoboyz9q.png" class="kg-image" alt loading="lazy" width="1270" height="1028" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-jqmgxaebesqgoewoboyz9q.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1-jqmgxaebesqgoewoboyz9q.png 1000w, https://blog.cmwang.net/content/images/max/800/1-jqmgxaebesqgoewoboyz9q.png 1270w" sizes="(min-width: 720px) 720px"><figcaption>The optimization time varies from 5 to 20 minutes depending on the hardware.</figcaption></figure><p>When the model optimization is complete, you need to activate this Endpoint. <strong>If you plan to fine-tune the threshold of the Endpoint, you need to deactivate it first</strong>. We also provide you with real-time inference screens and example code below.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1--fr9uckkys35zd4j4svptq.png" class="kg-image" alt loading="lazy" width="1062" height="900" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1--fr9uckkys35zd4j4svptq.png 600w, https://blog.cmwang.net/content/images/size/w1000/max/800/1--fr9uckkys35zd4j4svptq.png 1000w, https://blog.cmwang.net/content/images/max/800/1--fr9uckkys35zd4j4svptq.png 1062w" sizes="(min-width: 720px) 720px"><figcaption>Endpoint needs to be activated before it can operate properly.</figcaption></figure><p>At this point, the Endpoint is ready and you can send an HTTP Post Request with your familiar development language. The Endpoint will return the results in JSON format. Below is an example return with two possible objects.{<br> 'result': [{<br>  'xmin': 656.40967,<br>  'ymin': 427.88263,<br>  'width': 172,<br>  'height': 214,<br>  'label': 'mask',<br>  'confidence': 0.99844<br> }, {<br>  'xmin': 390.02213,<br>  'ymin': 724.0925,<br>  'width': 187,<br>  'height': 224,<br>  'label': 'face',<br>  'confidence': 0.99813914<br> }]<br>}</p><p>With the Python <a href="https://docs.python-requests.org/en/latest/?ref=localhost" rel="noopener">Request</a>s package, you can easily perform secondary development without writing complicated code, as shown in the following example:import requests<br>import jsonurl = 'http://192.168.41.200:52010/v1/infer/111111111' # change me# inference<br>files = {'<strong>image</strong>': open('assets/demo.jpg', 'rb')}<br>response = requests.post(url, files=files)<br>result = json.loads(response.text)<br>print(result)</p><p>Using the OpenCV package, you can also easily overlay the inference result on the image. I will provide a complete demonstration at the end of the article through the GitHub link.</p><p>The process of handling video streaming is also straightforward and consists of the following six steps. Repeat steps 2 to 6 until the video stream ends. Happy coding!1. Open image or stream<br>2. Capture Frame<br>3. Resize Frame<br>4. Perform inference via inference package (HTTP Post)<br>5. Process JSON output and draw boxes<br>6. Display Frame</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cmwang.net/content/images/max/800/1-x4vvphqmyj3japb3hrf5eq.gif" class="kg-image" alt loading="lazy" width="800" height="419" srcset="https://blog.cmwang.net/content/images/size/w600/max/800/1-x4vvphqmyj3japb3hrf5eq.gif 600w, https://blog.cmwang.net/content/images/max/800/1-x4vvphqmyj3japb3hrf5eq.gif 800w" sizes="(min-width: 720px) 720px"><figcaption>Video by cottonbro from Pexels: <a href="https://www.pexels.com/video/woman-art-iphone-smartphone-3960181/?ref=localhost" data-href="https://www.pexels.com/video/woman-art-iphone-smartphone-3960181/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://www.pexels.com/video/woman-art-iphone-smartphone-3960181/</a></figcaption></figure><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/nilvana-taka/nvir-mask-demo?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GitHub - nilvana-ai/nvir-mask-demo: This is a demo repo to demonstrate nilvana vision inference…</div><div class="kg-bookmark-description">This is a demo repo to demonstrate nilvana vision inference runtime. </div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-4rrzs0rllf0exjnd.png" alt></div></a></figure><!--kg-card-end: html--><!--kg-card-begin: html--><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://nilvana.ai/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Hello nilvana™, Hello Tomorrow</div><div class="kg-bookmark-description">AI Workstation, Jetson Nano, Xavier, Nvidia, Edge Computing, IoT, Edge Computing, 人工智慧，工作站，物聯網，邊緣運算，邊緣裝置。</div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.cmwang.net/content/images/fit/c/160/160/0-gegawc126g4zni92.jpg" alt></div></a></figure><!--kg-card-end: html-->
        </div>

    </article>

    <div class="gh-canvas">
    <div class="navigation">
            <a class="navigation-item navigation-next" href="/e9-80-8f-e9-81-8e-streamlit-e5-bf-ab-e9-80-9f-e5-bb-ba-e7-ab-8b-e7-89-a9-e9-ab-94-e5-81-b5-e6-b8-ac-web-app/">
                <span class="navigation-label">Next</span>
                <h4 class="navigation-title">Building an Object Detection App quickly with Streamlit</h4>
            </a>
    </div>
</div>


        <div class="related-wrapper gh-outer">
        <section class="related-posts gh-inner">
            <h3 class="related-title">
                <span class="text">You might also like...</span>
            </h3>
            <div class="post-feed">
                    <article class="post tag-plum tag-cui-mei tag-ceremony tag-life tag-family tag-hash-medium tag-hash-import-2024-02-01-00-16 u-shadow">
<a class="post-link" href="/e8-a3-bd-e4-bd-9c-e8-84-86-e6-a2-85-e7-9a-84-e6-99-82-e7-af-80-make-crispy-plum/">
        <figure class="post-media">
            <div class="u-placeholder same-height rectangle">
                <img
                    class="post-image u-object-fit"
                    srcset="/content/images/size/w400/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg 400w,
                            /content/images/size/w720/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg 750w,
                            /content/images/size/w960/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg 960w,
                            /content/images/size/w1200/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg 1140w,
                            /content/images/size/w2000/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg 1920w"
                    sizes="600px"
                    src="/content/images/size/w960/max/800/1-1kj9n9ovro9pacr9jkftsw.jpg"
                    alt="製作脆梅的時節 / Make Crispy Plum"
                    loading="lazy"
                >
            </div>
        </figure>

    <div class="post-wrapper">
        <header class="post-header">
                <span class="post-tag">Plum</span>

            <h2 class="post-title">
                製作脆梅的時節 / Make Crispy Plum
            </h2>
        </header>

            <div class="post-excerpt">
                製作脆梅一直是我們家重要的儀式，每年我們都會在年初與信義鄉的小農預訂青梅，並以此製作脆梅。
            </div>
    </div>

    <footer class="post-footer">
        <span class="post-more">Read More</span>
        <span class="post-time"><time class="post-card-meta-date" datetime="2023-04-16">Apr 16, 2023</time></span>

        <div class="post-author">
                    <span class="post-author-link">
                        <img class="post-author-image" src="/content/images/size/w150/v2/resize:fill:144:144/1-mzehvowngfwyye2pswx_vw.png" alt="Taka Wang" loading="lazy">
                    </span>
        </div>
    </footer>
</a>
</article>                    <article class="post tag-job-search tag-taipei tag-backend-development tag-data-science tag-tech-jobs tag-hash-medium tag-hash-import-2024-02-01-00-16 u-shadow">
<a class="post-link" href="/backing-up-a-stellar-data-engineer-open-for-new-opportunities-in-taipei/">
        <figure class="post-media">
            <div class="u-placeholder same-height rectangle">
                <img
                    class="post-image u-object-fit"
                    srcset="/content/images/size/w400/max/800/1-h3-aa9-_smfa7fsgn8kavw.png 400w,
                            /content/images/size/w720/max/800/1-h3-aa9-_smfa7fsgn8kavw.png 750w,
                            /content/images/size/w960/max/800/1-h3-aa9-_smfa7fsgn8kavw.png 960w,
                            /content/images/size/w1200/max/800/1-h3-aa9-_smfa7fsgn8kavw.png 1140w,
                            /content/images/size/w2000/max/800/1-h3-aa9-_smfa7fsgn8kavw.png 1920w"
                    sizes="600px"
                    src="/content/images/size/w960/max/800/1-h3-aa9-_smfa7fsgn8kavw.png"
                    alt="Backing Up a Stellar Data Engineer: Open for New Opportunities in Taipei"
                    loading="lazy"
                >
            </div>
        </figure>

    <div class="post-wrapper">
        <header class="post-header">
                <span class="post-tag">Jobsearch</span>

            <h2 class="post-title">
                Backing Up a Stellar Data Engineer: Open for New Opportunities in Taipei
            </h2>
        </header>

            <div class="post-excerpt">
                I am writing this post to recommend my colleague Jill Hsu for any relevant job opportunities in Taipei.
            </div>
    </div>

    <footer class="post-footer">
        <span class="post-more">Read More</span>
        <span class="post-time"><time class="post-card-meta-date" datetime="2023-03-23">Mar 23, 2023</time></span>

        <div class="post-author">
                    <span class="post-author-link">
                        <img class="post-author-image" src="/content/images/size/w150/v2/resize:fill:144:144/1-mzehvowngfwyye2pswx_vw.png" alt="Taka Wang" loading="lazy">
                    </span>
        </div>
    </footer>
</a>
</article>                    <article class="post tag-industrial-camera-systems tag-embedded-systems tag-u3v tag-computer-vision tag-machine-vision-system tag-hash-medium tag-hash-import-2024-02-01-00-16 u-shadow">
<a class="post-link" href="/configuring-usb-fs-for-usb3-vision-camera/">
        <figure class="post-media">
            <div class="u-placeholder same-height rectangle">
                <img
                    class="post-image u-object-fit"
                    srcset="/content/images/size/w400/max/800/1-uoy9jp33j7xif2emebtdcg.jpg 400w,
                            /content/images/size/w720/max/800/1-uoy9jp33j7xif2emebtdcg.jpg 750w,
                            /content/images/size/w960/max/800/1-uoy9jp33j7xif2emebtdcg.jpg 960w,
                            /content/images/size/w1200/max/800/1-uoy9jp33j7xif2emebtdcg.jpg 1140w,
                            /content/images/size/w2000/max/800/1-uoy9jp33j7xif2emebtdcg.jpg 1920w"
                    sizes="600px"
                    src="/content/images/size/w960/max/800/1-uoy9jp33j7xif2emebtdcg.jpg"
                    alt="Configuring USB-FS for USB3 Vision Camera"
                    loading="lazy"
                >
            </div>
        </figure>

    <div class="post-wrapper">
        <header class="post-header">
                <span class="post-tag">Industrial Camera Systems</span>

            <h2 class="post-title">
                Configuring USB-FS for USB3 Vision Camera
            </h2>
        </header>

            <div class="post-excerpt">
                This post explains how to increase the buffer memory for USB-FS devices on Linux systems.
            </div>
    </div>

    <footer class="post-footer">
        <span class="post-more">Read More</span>
        <span class="post-time"><time class="post-card-meta-date" datetime="2022-12-29">Dec 29, 2022</time></span>

        <div class="post-author">
                    <span class="post-author-link">
                        <img class="post-author-image" src="/content/images/size/w150/v2/resize:fill:144:144/1-mzehvowngfwyye2pswx_vw.png" alt="Taka Wang" loading="lazy">
                    </span>
        </div>
    </footer>
</a>
</article>                    <article class="post tag-computer-vision tag-artificial-intelligence tag-deep-learning tag-ai tag-jetson-nano tag-hash-medium tag-hash-import-2024-02-01-00-16 u-shadow">
<a class="post-link" href="/how-to-install-people-counting-toolkit-on-your-jetson-devices/">
        <figure class="post-media">
            <div class="u-placeholder same-height rectangle">
                <img
                    class="post-image u-object-fit"
                    srcset="/content/images/size/w400/max/800/1-2zavqgypzo5yujkr_uzflq.jpg 400w,
                            /content/images/size/w720/max/800/1-2zavqgypzo5yujkr_uzflq.jpg 750w,
                            /content/images/size/w960/max/800/1-2zavqgypzo5yujkr_uzflq.jpg 960w,
                            /content/images/size/w1200/max/800/1-2zavqgypzo5yujkr_uzflq.jpg 1140w,
                            /content/images/size/w2000/max/800/1-2zavqgypzo5yujkr_uzflq.jpg 1920w"
                    sizes="600px"
                    src="/content/images/size/w960/max/800/1-2zavqgypzo5yujkr_uzflq.jpg"
                    alt="How to install People Counting Toolkit on your Jetson devices"
                    loading="lazy"
                >
            </div>
        </figure>

    <div class="post-wrapper">
        <header class="post-header">
                <span class="post-tag">Computer Vision</span>

            <h2 class="post-title">
                How to install People Counting Toolkit on your Jetson devices
            </h2>
        </header>

            <div class="post-excerpt">
                The installation procedure is quite simple — bash &lt;(curl -fsSL https://links.nilvana.ai/get-pc)
            </div>
    </div>

    <footer class="post-footer">
        <span class="post-more">Read More</span>
        <span class="post-time"><time class="post-card-meta-date" datetime="2022-09-28">Sep 28, 2022</time></span>

        <div class="post-author">
                    <span class="post-author-link">
                        <img class="post-author-image" src="/content/images/size/w150/v2/resize:fill:144:144/1-mzehvowngfwyye2pswx_vw.png" alt="Taka Wang" loading="lazy">
                    </span>
        </div>
    </footer>
</a>
</article>            </div>
        </section>
</div>
</main>
    </div>

    <footer class="gh-foot no-menu gh-outer">
        <div class="gh-foot-inner gh-inner">
            <div class="gh-copyright">
                Liberation Notes © 2024
            </div>
            <div class="gh-powered-by">
                <a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a>
            </div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script src="/assets/built/main.min.js?v=69d004e056"></script>

<style>
.gh-foot-menu {
    display: none;
}

.gh-powered-by {
    display: none;
}
.gh-footer-copyright {
  display: none;
}
</style>

</body>
</html>